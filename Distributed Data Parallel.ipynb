{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Data Parallel Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 1\n",
    "world_size = 2\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "    \n",
    "\n",
    "setup(rank, world_size)\n",
    "\n",
    "# create model and move it to GPU with id rank\n",
    "model = model().to(rank)\n",
    "ddp_model = DDP(model, device_ids=[rank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global epoch #declear epoch global, to be used later by torch.save() \n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    ave_loss = 0\n",
    "    global loss #declear loss global, to be used later by torch.save() \n",
    "    for batch_idx, diction in enumerate(train_loader):\n",
    "        model.train() #set model to traning mode\n",
    "        optimizer.zero_grad()\n",
    "        x, target = diction['image'], diction['rating'] #extract training data for this batch\n",
    "        # target = target.resize_(20)\n",
    "        x, target = x.float(), target.float() #set datatype\n",
    "        x, target = x.torch.nn.DataParallel(x), torch.nn.DataParallel(target) #transfer to GPU\n",
    "        x, target = Variable(x), Variable(target) #set to pytorch datatype: variable\n",
    "        out = model(x) #forward pass\n",
    "        loss = criterion(out, target) #calculate loss\n",
    "        ave_loss = ave_loss * 0.9 + loss.item() * 0.1 \n",
    "        loss.backward() #back propagation with calculated loss\n",
    "        optimizer.step() #calculate gradient and step\n",
    "        if (batch_idx + 1) % 100 == 0 or (batch_idx + 1) == len(train_loader):\n",
    "            print('==>>> epoch: {}, batch index: {}, train loss: {:.6f}'.format(epoch, batch_idx + 1, loss))\n",
    "\n",
    "    correct_cnt, ave_loss = 0, 0\n",
    "    total_cnt = 0\n",
    "    for batch_idx, diction in enumerate(val_loader):\n",
    "        model.eval() #set model to evaluation mode\n",
    "        x, target = diction['image'], diction['rating']\n",
    "        # SStarget = target.resize_(20)\n",
    "        x, target = x.float(), target.float()\n",
    "        x, target = x.to(device), target.to(device)\n",
    "        x, target = Variable(x), Variable(target)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target)\n",
    "        pred_label = out.data.int().float().resize_(20) \n",
    "        # make out.data int to remove decimals, revert to float and resize for the datatype to match when using .sum()\n",
    "        total_cnt += x.data.size()[0]\n",
    "        correct_cnt += (pred_label == target.data).sum()\n",
    "        ave_loss = ave_loss * 0.9 + loss.item() * 0.1 #smooth average\n",
    "        if (batch_idx + 1) % 100 == 0 or (batch_idx + 1) == len(val_loader):\n",
    "            print(\n",
    "            '==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
    "                epoch, batch_idx + 1, ave_loss, correct_cnt.item() * 1.0 / total_cnt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
