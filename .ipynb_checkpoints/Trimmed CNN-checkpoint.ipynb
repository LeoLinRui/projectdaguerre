{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from skimage import transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "#MNIST 1x28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = r\"C:\\Users\\Leo's PC\\PycharmProjects\\PD\\MNIST\"\n",
    "data_transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "MNIST_train = torchvision.datasets.MNIST(dataset_root, train=True, transform=data_transform, target_transform=None, download=True)\n",
    "MNIST_val = torchvision.datasets.MNIST(dataset_root, train=False, transform=data_transform, target_transform=None, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=MNIST_train, batch_size=20,shuffle=True) # 3000 batches\n",
    "val_loader = DataLoader(dataset=MNIST_val, batch_size=20, shuffle=False) # 500 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_combine(a, b):\n",
    "    if a.shape[2] < b.shape[2]:\n",
    "        factor = b.shape[2] / a.shape[2]\n",
    "        a = functional.upsample(a, scale_factor=factor)\n",
    "    elif a.shape[2] > b.shape[2]:\n",
    "        factor = a.shape[2] / b.shape[2]\n",
    "        b = functional.upsample(b, scale_factor=factor)\n",
    "        \n",
    "    idx0 = 0\n",
    "    for img in a:\n",
    "        idx1 = 0\n",
    "        for channel_a in img:\n",
    "            channel_a = channel_a.add(b[idx0][idx1]) / 2\n",
    "            idx1 += 1\n",
    "        idx0 += 1\n",
    "    \n",
    "    return a\n",
    "\n",
    "\n",
    "class TCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TCNN, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        \n",
    "        self.pool2_B = nn.MaxPool2d(kernel_size = [4, 4], stride=2, padding=0)\n",
    "        self.pool2_S = nn.MaxPool2d(kernel_size = [2, 2], stride=4, padding=0)\n",
    "        \n",
    "        self.conv2_B = nn.Conv2d(in_channels=8, out_channels=64, kernel_size=[4,4], stride=1)\n",
    "        self.conv2_S = nn.Conv2d(in_channels=24, out_channels=64, kernel_size=[2,2], stride=1)\n",
    "        self.activation2 = nn.ReLU()\n",
    "        \n",
    "        self.pool3_B = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=0)\n",
    "        self.pool3_S = nn.MaxPool2d(kernel_size = [4, 4], stride=4, padding=1)\n",
    "        \n",
    "        self.conv3_B = nn.Conv2d(in_channels=16, out_channels=128, kernel_size=[4,4], stride=1, padding=1)\n",
    "        self.conv3_S = nn.Conv2d(in_channels=48, out_channels=128, kernel_size=[2,2], stride=1, padding=1)\n",
    "        self.activation3 = nn.ReLU()\n",
    "        \n",
    "        # fc1 has 2048 inputs\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.activation1(x)\n",
    "          \n",
    "        x_0, x_1 = torch.split(x, [8, 24], dim=1)\n",
    "        x_0 = self.pool2_B(x_0)\n",
    "        x_1 = self.pool2_S(x_1)\n",
    "        \n",
    "        x_0, x_1 = self.conv2_B(x_0), self.conv2_S(x_1)\n",
    "        x = avg_combine(x_0, x_1) # combine 64 feature maps on both sides into one (after upsampling the small one)\n",
    "        x = self.activation2(x)\n",
    "\n",
    "        \n",
    "        x_0, x_1 = torch.split(x, [16, 48], dim=1)\n",
    "        x_0 = self.pool3_B(x_0)\n",
    "        x_1 = self.pool3_S(x_1) \n",
    "        \n",
    "        x_0, x_1 = self.conv3_B(x_0), self.conv3_S(x_1)\n",
    "        x = avg_combine(x_0, x_1)\n",
    "        x = self.activation3(x)\n",
    "        x = x = x.view(x.size()[0], -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.Sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.Sigmoid(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.Softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCNN(\n",
       "  (conv1_1): Conv2d(1, 32, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
       "  (activation1): ReLU()\n",
       "  (pool2_B): MaxPool2d(kernel_size=[4, 4], stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool2_S): MaxPool2d(kernel_size=[2, 2], stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2_B): Conv2d(8, 64, kernel_size=[4, 4], stride=(1, 1))\n",
       "  (conv2_S): Conv2d(24, 64, kernel_size=[2, 2], stride=(1, 1))\n",
       "  (activation2): ReLU()\n",
       "  (pool3_B): MaxPool2d(kernel_size=[2, 2], stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool3_S): MaxPool2d(kernel_size=[4, 4], stride=4, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv3_B): Conv2d(16, 128, kernel_size=[4, 4], stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_S): Conv2d(48, 128, kernel_size=[2, 2], stride=(1, 1), padding=(1, 1))\n",
       "  (activation3): ReLU()\n",
       "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (Sigmoid): Sigmoid()\n",
       "  (Softmax): Softmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_embedding(labels, num_classes):\n",
    "    \"\"\"Embedding labels to one-hot form.\n",
    "\n",
    "    Args:\n",
    "      labels: (LongTensor) class labels, sized [N,].\n",
    "      num_classes: (int) number of classes.\n",
    "\n",
    "    Returns:\n",
    "      (tensor) encoded labels, sized [N, #classes].\n",
    "    \"\"\"\n",
    "    y = torch.eye(num_classes) \n",
    "    return y[labels]\n",
    "\n",
    "model = TCNN()\n",
    "\n",
    "model = model.cuda()\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n"
     ]
    }
   ],
   "source": [
    "sample = torch.Tensor(np.zeros(784).reshape(1, 1, 28, 28))\n",
    "sample = sample.cuda()\n",
    "sample = sample.to(device)\n",
    "prediction = model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCNN(\n",
       "  (conv1_1): Conv2d(1, 32, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
       "  (activation1): ReLU()\n",
       "  (pool2_B): MaxPool2d(kernel_size=[4, 4], stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool2_S): MaxPool2d(kernel_size=[2, 2], stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2_B): Conv2d(8, 64, kernel_size=[4, 4], stride=(1, 1))\n",
       "  (conv2_S): Conv2d(24, 64, kernel_size=[2, 2], stride=(1, 1))\n",
       "  (activation2): ReLU()\n",
       "  (pool3_B): MaxPool2d(kernel_size=[2, 2], stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool3_S): MaxPool2d(kernel_size=[4, 4], stride=4, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv3_B): Conv2d(16, 128, kernel_size=[4, 4], stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_S): Conv2d(48, 128, kernel_size=[2, 2], stride=(1, 1), padding=(1, 1))\n",
       "  (activation3): ReLU()\n",
       "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (Sigmoid): Sigmoid()\n",
       "  (Softmax): Softmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global epoch #declear epoch global, to be used later by torch.save() \n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    ave_loss = 0\n",
    "    global loss #declear loss global, to be used later by torch.save() \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        model.train() #set model to traning mode\n",
    "        optimizer.zero_grad()\n",
    "        data, target = data.float(), target.float() #set datatype\n",
    "        data, target = data.to(device), target.to(device) #transfer to GPU\n",
    "        data, target = Variable(data), Variable(target) #set to pytorch datatype: variable\n",
    "        out = model(data) #forward pass\n",
    "        loss = criterion(out, target.long()) #calculate loss\n",
    "        ave_loss = ave_loss * 0.9 + loss.item() * 0.1 \n",
    "        loss.backward() #back propagation with calculated loss\n",
    "        optimizer.step() #calculate gradient and step\n",
    "        if (batch_idx + 1) % 100 == 0 or (batch_idx + 1) == len(train_loader):\n",
    "            print('==>>> epoch: {}, batch index: {}, train loss: {:.6f}'.format(epoch, batch_idx + 1, loss))\n",
    "\n",
    "    correct_cnt, ave_loss = 0, 0\n",
    "    total_cnt = 0\n",
    "    for batch_idx, (data, target) in enumerate(val_loader):\n",
    "        model.eval() #set model to evaluation mode\n",
    "        data, target = data.float(), target.float() #set datatype\n",
    "        data, target = data.to(device), target.to(device) #transfer to GPU\n",
    "        data, target = Variable(data), Variable(target) #set to pytorch datatype: variable\n",
    "       \n",
    "        out = model(data)\n",
    "        loss = criterion(out, target.long()) #calculate loss\n",
    "\n",
    "        pred_label = out.data\n",
    "        target = target.long()\n",
    "        \n",
    "        target_onehot = one_hot_embedding(target.data, 10)\n",
    "        target_onehot = target_onehot.to(device)\n",
    "        \n",
    "        total_cnt += data.data.size()[0]\n",
    "        correct_cnt += (pred_label == target_onehot).sum()\n",
    "        ave_loss = ave_loss * 0.9 + loss.item() * 0.1 #smooth average\n",
    "        \n",
    "        if (batch_idx + 1) % 100 == 0 or (batch_idx + 1) == len(val_loader):\n",
    "            print(\n",
    "            '==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
    "                epoch, batch_idx + 1, ave_loss, correct_cnt.item() * 1.0 / total_cnt))\n",
    "            print(pred_label.data, target.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
