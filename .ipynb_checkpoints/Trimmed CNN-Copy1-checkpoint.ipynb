{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from skimage import transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "#MNIST 1x28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_root = r\"C:\\Users\\Leo's PC\\PycharmProjects\\PD\\MNIST\"\n",
    "data_transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "MNIST_train = torchvision.datasets.MNIST(MNIST_root, train=True, transform=data_transform, target_transform=None, download=True)\n",
    "MNIST_val = torchvision.datasets.MNIST(MNIST_root, train=False, transform=data_transform, target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to C:\\Users\\Leo's PC\\PycharmProjects\\PD\\CIFAR10\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\Leo's PC\\PycharmProjects\\PD\\CIFAR10\\cifar-10-python.tar.gz to C:\\Users\\Leo's PC\\PycharmProjects\\PD\\CIFAR10\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CIFAR10_root = r\"C:\\Users\\Leo's PC\\PycharmProjects\\PD\\CIFAR10\"\n",
    "\n",
    "CIFAR10_train = torchvision.datasets.CIFAR10(CIFAR10_root, train=True, transform=data_transform, target_transform=None, download=True)\n",
    "CIFAR10_val = torchvision.datasets.CIFAR10(CIFAR10_root, train=False, transform=data_transform, target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=CIFAR10_train, batch_size=100,shuffle=True) # 3000 batches\n",
    "val_loader = DataLoader(dataset=CIFAR10_val, batch_size=100, shuffle=False) # 500 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_combine(a, b):\n",
    "    if a.shape[2] < b.shape[2]:\n",
    "        a = functional.upsample(a, scale_factor=(b.shape[2] / a.shape[2]))\n",
    "    elif a.shape[2] > b.shape[2]:\n",
    "        b = functional.upsample(b, scale_factor=(a.shape[2] / b.shape[2]))\n",
    "        \n",
    "    idx0 = 0\n",
    "    for img in a:\n",
    "        idx1 = 0\n",
    "        for channel_a in img:\n",
    "            channel_a = channel_a.add(b[idx0][idx1]) / 2\n",
    "            idx1 += 1\n",
    "        idx0 += 1\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=0)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=[3,3], stride=1)\n",
    "        self.activation2 = nn.ReLU()\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=0)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation3 = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(3200, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation1(x)\n",
    "        \n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.activation2(x)\n",
    "        \n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.activation3(x)\n",
    "          \n",
    "        x = x.view(x.size()[0], -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.Sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.Sigmoid(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.Softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TCNN, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        \n",
    "        self.pool2_B = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=0)\n",
    "        self.pool2_S = nn.MaxPool2d(kernel_size = [4, 4], stride=4, padding=0)\n",
    "        \n",
    "        self.conv2_B = nn.Conv2d(in_channels=8, out_channels=64, kernel_size=[3,3], stride=1)\n",
    "        self.conv2_S = nn.Conv2d(in_channels=24, out_channels=64, kernel_size=[3,3], stride=1)\n",
    "        self.activation2 = nn.ReLU()\n",
    "        \n",
    "        self.pool3_B = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=0)\n",
    "        self.pool3_S = nn.MaxPool2d(kernel_size = [4, 4], stride=4, padding=0)\n",
    "        \n",
    "        self.conv3_B = nn.Conv2d(in_channels=16, out_channels=128, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.conv3_S = nn.Conv2d(in_channels=48, out_channels=128, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation3 = nn.ReLU()\n",
    "        \n",
    "        # fc1 has 2048 inputs\n",
    "        self.fc1 = nn.Linear(3200, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.activation1(x)\n",
    "          \n",
    "        x_0, x_1 = torch.split(x, [8, 24], dim=1)\n",
    "        x_0 = self.pool2_B(x_0)\n",
    "        x_1 = self.pool2_S(x_1)\n",
    "        \n",
    "        x_0, x_1 = self.conv2_B(x_0), self.conv2_S(x_1)\n",
    "        x = avg_combine(x_0, x_1) # combine 64 feature maps on both sides into one (after upsampling the small one)\n",
    "        x = self.activation2(x)\n",
    "\n",
    "        \n",
    "        x_0, x_1 = torch.split(x, [16, 48], dim=1)\n",
    "        x_0 = self.pool3_B(x_0)\n",
    "        x_1 = self.pool3_S(x_1) \n",
    "        \n",
    "        x_0, x_1 = self.conv3_B(x_0), self.conv3_S(x_1)\n",
    "        x = avg_combine(x_0, x_1)\n",
    "        x = self.activation3(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.Sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.Sigmoid(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.Softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCNN(\n",
       "  (conv1_1): Conv2d(3, 32, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
       "  (activation1): ReLU()\n",
       "  (pool2_B): MaxPool2d(kernel_size=[4, 4], stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool2_S): MaxPool2d(kernel_size=[2, 2], stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2_B): Conv2d(8, 64, kernel_size=[4, 4], stride=(1, 1))\n",
       "  (conv2_S): Conv2d(24, 64, kernel_size=[2, 2], stride=(1, 1))\n",
       "  (activation2): ReLU()\n",
       "  (pool3_B): MaxPool2d(kernel_size=[2, 2], stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool3_S): MaxPool2d(kernel_size=[4, 4], stride=4, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv3_B): Conv2d(16, 128, kernel_size=[4, 4], stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_S): Conv2d(48, 128, kernel_size=[2, 2], stride=(1, 1), padding=(1, 1))\n",
       "  (activation3): ReLU()\n",
       "  (fc1): Linear(in_features=3200, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (Sigmoid): Sigmoid()\n",
       "  (Softmax): Softmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_embedding(labels, num_classes):\n",
    "    \"\"\"Embedding labels to one-hot form.\n",
    "\n",
    "    Args:\n",
    "      labels: (LongTensor) class labels, sized [N,].\n",
    "      num_classes: (int) number of classes.\n",
    "\n",
    "    Returns:\n",
    "      (tensor) encoded labels, sized [N, #classes].\n",
    "    \"\"\"\n",
    "    y = torch.eye(num_classes) \n",
    "    return y[labels]\n",
    "\n",
    "model = TCNN()\n",
    "\n",
    "model = model.cuda()\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCNN(\n",
       "  (conv1_1): Conv2d(3, 32, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
       "  (activation1): ReLU()\n",
       "  (pool2_B): MaxPool2d(kernel_size=[4, 4], stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool2_S): MaxPool2d(kernel_size=[2, 2], stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2_B): Conv2d(8, 64, kernel_size=[4, 4], stride=(1, 1))\n",
       "  (conv2_S): Conv2d(24, 64, kernel_size=[2, 2], stride=(1, 1))\n",
       "  (activation2): ReLU()\n",
       "  (pool3_B): MaxPool2d(kernel_size=[2, 2], stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool3_S): MaxPool2d(kernel_size=[4, 4], stride=4, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv3_B): Conv2d(16, 128, kernel_size=[4, 4], stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_S): Conv2d(48, 128, kernel_size=[2, 2], stride=(1, 1), padding=(1, 1))\n",
       "  (activation3): ReLU()\n",
       "  (fc1): Linear(in_features=3200, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (Sigmoid): Sigmoid()\n",
       "  (Softmax): Softmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 0, batch index: 100, train loss: 2.302543\n",
      "==>>> epoch: 0, batch index: 200, train loss: 2.302330\n",
      "==>>> epoch: 0, batch index: 300, train loss: 2.294877\n",
      "==>>> epoch: 0, batch index: 400, train loss: 2.290797\n",
      "==>>> epoch: 0, batch index: 500, train loss: 2.288031\n",
      "==>>> epoch: 0, batch index: 100, test loss: 2.278960, acc: 0.272\n",
      "==>>> epoch: 1, batch index: 100, train loss: 2.278116\n",
      "==>>> epoch: 1, batch index: 200, train loss: 2.266853\n",
      "==>>> epoch: 1, batch index: 300, train loss: 2.283905\n",
      "==>>> epoch: 1, batch index: 400, train loss: 2.275617\n",
      "==>>> epoch: 1, batch index: 500, train loss: 2.261864\n",
      "==>>> epoch: 1, batch index: 100, test loss: 2.255310, acc: 0.346\n",
      "==>>> epoch: 2, batch index: 100, train loss: 2.259526\n",
      "==>>> epoch: 2, batch index: 200, train loss: 2.252813\n",
      "==>>> epoch: 2, batch index: 300, train loss: 2.256556\n",
      "==>>> epoch: 2, batch index: 400, train loss: 2.251159\n",
      "==>>> epoch: 2, batch index: 500, train loss: 2.257559\n",
      "==>>> epoch: 2, batch index: 100, test loss: 2.248623, acc: 0.377\n",
      "==>>> epoch: 3, batch index: 100, train loss: 2.264585\n",
      "==>>> epoch: 3, batch index: 200, train loss: 2.260138\n",
      "==>>> epoch: 3, batch index: 300, train loss: 2.267459\n",
      "==>>> epoch: 3, batch index: 400, train loss: 2.246020\n",
      "==>>> epoch: 3, batch index: 500, train loss: 2.250936\n",
      "==>>> epoch: 3, batch index: 100, test loss: 2.244846, acc: 0.399\n",
      "==>>> epoch: 4, batch index: 100, train loss: 2.228696\n",
      "==>>> epoch: 4, batch index: 200, train loss: 2.250192\n",
      "==>>> epoch: 4, batch index: 300, train loss: 2.244769\n",
      "==>>> epoch: 4, batch index: 400, train loss: 2.233467\n",
      "==>>> epoch: 4, batch index: 500, train loss: 2.250060\n",
      "==>>> epoch: 4, batch index: 100, test loss: 2.243882, acc: 0.426\n",
      "==>>> epoch: 5, batch index: 100, train loss: 2.262279\n",
      "==>>> epoch: 5, batch index: 200, train loss: 2.238395\n",
      "==>>> epoch: 5, batch index: 300, train loss: 2.243561\n",
      "==>>> epoch: 5, batch index: 400, train loss: 2.232816\n",
      "==>>> epoch: 5, batch index: 500, train loss: 2.230970\n",
      "==>>> epoch: 5, batch index: 100, test loss: 2.241339, acc: 0.432\n",
      "==>>> epoch: 6, batch index: 100, train loss: 2.232105\n",
      "==>>> epoch: 6, batch index: 200, train loss: 2.252304\n",
      "==>>> epoch: 6, batch index: 300, train loss: 2.226579\n",
      "==>>> epoch: 6, batch index: 400, train loss: 2.223217\n"
     ]
    }
   ],
   "source": [
    "global epoch #declear epoch global, to be used later by torch.save() \n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "\n",
    "    ave_loss = 0\n",
    "    global loss #declear loss global, to be used later by torch.save() \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        model.train() #set model to traning mode\n",
    "        optimizer.zero_grad()\n",
    "        data, target = data.float(), target.float() #set datatype\n",
    "        data, target = data.to(device), target.to(device) #transfer to GPU\n",
    "        data, target = Variable(data), Variable(target) #set to pytorch datatype: variable\n",
    "        out = model(data) #forward pass\n",
    "        loss = criterion(out, target.long()) #calculate loss\n",
    "        ave_loss = ave_loss * 0.9 + loss.item() * 0.1 \n",
    "        loss.backward() #back propagation with calculated loss\n",
    "        optimizer.step() #calculate gradient and step\n",
    "        if (batch_idx + 1) % 100 == 0 or (batch_idx + 1) == len(train_loader):\n",
    "            print('==>>> epoch: {}, batch index: {}, train loss: {:.6f}'.format(epoch, batch_idx + 1, loss))\n",
    "\n",
    "    correct, ave_loss = 0, 0\n",
    "    total_cnt = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(val_loader):\n",
    "        model.eval() #set model to evaluation mode\n",
    "        data, target = data.float(), target.float() #set datatype\n",
    "        data, target = data.to(device), target.to(device) #transfer to GPU\n",
    "        data, target = Variable(data), Variable(target) #set to pytorch datatype: variable\n",
    "       \n",
    "        out = model(data)\n",
    "        loss = criterion(out, target.long()) #calculate loss\n",
    "\n",
    "        pred_label = out.data\n",
    "        pred_label = pred_label.argmax(dim=1, keepdim=True)\n",
    "        \n",
    "        target = target.long()\n",
    "        target_onehot = one_hot_embedding(target.data, 10)\n",
    "        target_onehot = target_onehot.to(device)\n",
    "        \n",
    "        total_cnt += data.data.size()[0]\n",
    "        ave_loss = ave_loss * 0.9 + loss.item() * 0.1 #smooth average\n",
    "        correct += pred_label.eq(target.view_as(pred_label)).sum().item()\n",
    "        \n",
    "        if (batch_idx + 1) % 100 == 0 or (batch_idx + 1) == len(val_loader):\n",
    "            print(\n",
    "            '==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
    "                epoch, batch_idx + 1, ave_loss, correct * 1.0 / total_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.Tensor(np.zeros(784).reshape(1, 1, 28, 28))\n",
    "sample = sample.cuda()\n",
    "sample = sample.to(device)\n",
    "prediction = model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2303050\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
