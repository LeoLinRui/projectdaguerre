{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from skimage import transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "#MNIST 1x28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_root = r\"C:\\Users\\Leo's PC\\PycharmProjects\\PD\\MNIST\"\n",
    "data_transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "MNIST_train = torchvision.datasets.MNIST(dataset_root, train=True, transform=data_transform, target_transform=None, download=True)\n",
    "MNIST_val = torchvision.datasets.MNIST(dataset_root, train=False, transform=data_transform, target_transform=None, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=MNIST_train, batch_size=100,shuffle=True) # 600 batches\n",
    "val_loader = DataLoader(dataset=MNIST_val, batch_size=100, shuffle=False) # 100 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Avg_Combine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Avg_Combine, self).__init__()\n",
    "        \n",
    "    def forward(self, a, b):\n",
    "        if a.shape[2] < b.shape[2]:\n",
    "            factor = b.shape[2] / a.shape[2]\n",
    "            a = functional.interpolate(a, scale_factor=factor)\n",
    "        elif a.shape[2] > b.shape[2]:\n",
    "            factor = a.shape[2] / b.shape[2]\n",
    "            b = functional.interpolate(b, scale_factor=factor)\n",
    "        \n",
    "        idx0 = 0\n",
    "        for img in a:\n",
    "            idx1 = 0\n",
    "            for channel_a in img:\n",
    "                channel_a = channel_a.add(b[idx0][idx1]) / 2\n",
    "                idx1 += 1\n",
    "            idx0 += 1\n",
    "    \n",
    "        return a   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TCNN, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        \n",
    "        self.pool2_B = nn.MaxPool2d(kernel_size = [4, 4], stride=2, padding=0)\n",
    "        self.pool2_S = nn.MaxPool2d(kernel_size = [2, 2], stride=4, padding=0)\n",
    "        \n",
    "        self.conv2_B = nn.Conv2d(in_channels=8, out_channels=64, kernel_size=[4,4], stride=1)\n",
    "        self.conv2_S = nn.Conv2d(in_channels=24, out_channels=64, kernel_size=[2,2], stride=1)\n",
    "        self.activation2 = nn.ReLU()\n",
    "        \n",
    "        self.pool3_B = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=0)\n",
    "        self.pool3_S = nn.MaxPool2d(kernel_size = [4, 4], stride=4, padding=1)\n",
    "        \n",
    "        self.conv3_B = nn.Conv2d(in_channels=16, out_channels=128, kernel_size=[4,4], stride=1, padding=1)\n",
    "        self.conv3_S = nn.Conv2d(in_channels=48, out_channels=128, kernel_size=[2,2], stride=1, padding=1)\n",
    "        self.activation3 = nn.ReLU()\n",
    "        \n",
    "        # fc1 has 2048 inputs\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "        self.avg_combine = Avg_Combine()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.activation1(x)\n",
    "          \n",
    "        x_0, x_1 = torch.split(x, [8, 24], dim=1)\n",
    "        x_0 = self.pool2_B(x_0)\n",
    "        x_1 = self.pool2_S(x_1)\n",
    "        \n",
    "        x_0, x_1 = self.conv2_B(x_0), self.conv2_S(x_1)\n",
    "        x = self.avg_combine(x_0, x_1) # combine 64 feature maps on both sides into one (after upsampling the small one)\n",
    "        x = self.activation2(x)\n",
    "\n",
    "        \n",
    "        x_0, x_1 = torch.split(x, [16, 48], dim=1)\n",
    "        x_0 = self.pool3_B(x_0)\n",
    "        x_1 = self.pool3_S(x_1) \n",
    "        \n",
    "        x_0, x_1 = self.conv3_B(x_0), self.conv3_S(x_1)\n",
    "        x = self.avg_combine(x_0, x_1)\n",
    "        x = self.activation3(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.Sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.Sigmoid(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.Softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=0)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=[4,4], stride=1)\n",
    "        self.activation2 = nn.ReLU()\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=0)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=[4,4], stride=1, padding=1)\n",
    "        self.activation3 = nn.ReLU()\n",
    "        \n",
    "        # fc1 has 2048 inputs\n",
    "        self.fc1 = nn.Linear(2048, 10)\n",
    "        \n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation1(x)\n",
    "        \n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.activation2(x)\n",
    "        \n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.activation3(x)\n",
    "          \n",
    "        x = x.view(x.size()[0], -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.Softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCNN(\n",
       "  (conv1_1): Conv2d(1, 32, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
       "  (activation1): ReLU()\n",
       "  (pool2_B): MaxPool2d(kernel_size=[4, 4], stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool2_S): MaxPool2d(kernel_size=[2, 2], stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2_B): Conv2d(8, 64, kernel_size=[4, 4], stride=(1, 1))\n",
       "  (conv2_S): Conv2d(24, 64, kernel_size=[2, 2], stride=(1, 1))\n",
       "  (activation2): ReLU()\n",
       "  (pool3_B): MaxPool2d(kernel_size=[2, 2], stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool3_S): MaxPool2d(kernel_size=[4, 4], stride=4, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv3_B): Conv2d(16, 128, kernel_size=[4, 4], stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_S): Conv2d(48, 128, kernel_size=[2, 2], stride=(1, 1), padding=(1, 1))\n",
       "  (activation3): ReLU()\n",
       "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (Sigmoid): Sigmoid()\n",
       "  (Softmax): Softmax(dim=0)\n",
       "  (avg_combine): Avg_Combine()\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_embedding(labels, num_classes):\n",
    "    \"\"\"Embedding labels to one-hot form.\n",
    "\n",
    "    Args:\n",
    "      labels: (LongTensor) class labels, sized [N,].\n",
    "      num_classes: (int) number of classes.\n",
    "\n",
    "    Returns:\n",
    "      (tensor) encoded labels, sized [N, #classes].\n",
    "    \"\"\"\n",
    "    y = torch.eye(num_classes) \n",
    "    return y[labels]\n",
    "\n",
    "model = TCNN()\n",
    "\n",
    "model = model.cuda()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCNN(\n",
       "  (conv1_1): Conv2d(1, 32, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
       "  (activation1): ReLU()\n",
       "  (pool2_B): MaxPool2d(kernel_size=[4, 4], stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool2_S): MaxPool2d(kernel_size=[2, 2], stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2_B): Conv2d(8, 64, kernel_size=[4, 4], stride=(1, 1))\n",
       "  (conv2_S): Conv2d(24, 64, kernel_size=[2, 2], stride=(1, 1))\n",
       "  (activation2): ReLU()\n",
       "  (pool3_B): MaxPool2d(kernel_size=[2, 2], stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool3_S): MaxPool2d(kernel_size=[4, 4], stride=4, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv3_B): Conv2d(16, 128, kernel_size=[4, 4], stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_S): Conv2d(48, 128, kernel_size=[2, 2], stride=(1, 1), padding=(1, 1))\n",
       "  (activation3): ReLU()\n",
       "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (Sigmoid): Sigmoid()\n",
       "  (Softmax): Softmax(dim=0)\n",
       "  (avg_combine): Avg_Combine()\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 0, batch index: 100, train loss avg: 2.283930\n",
      "==>>> epoch: 0, batch index: 200, train loss avg: 2.246003\n",
      "==>>> epoch: 0, batch index: 300, train loss avg: 2.231600\n",
      "==>>> epoch: 0, batch index: 400, train loss avg: 2.223202\n",
      "==>>> epoch: 0, batch index: 500, train loss avg: 2.220215\n",
      "==>>> epoch: 0, batch index: 600, train loss avg: 2.218302\n",
      "==>>> epoch: 0, batch index: 100, test loss: 2.218362, acc: 0.873\n",
      "==>>> epoch: 1, batch index: 100, train loss avg: 2.217690\n",
      "==>>> epoch: 1, batch index: 200, train loss avg: 2.216404\n",
      "==>>> epoch: 1, batch index: 300, train loss avg: 2.216089\n",
      "==>>> epoch: 1, batch index: 400, train loss avg: 2.215819\n",
      "==>>> epoch: 1, batch index: 500, train loss avg: 2.215628\n",
      "==>>> epoch: 1, batch index: 600, train loss avg: 2.215620\n",
      "==>>> epoch: 1, batch index: 100, test loss: 2.215426, acc: 0.898\n",
      "==>>> epoch: 2, batch index: 100, train loss avg: 2.215406\n",
      "==>>> epoch: 2, batch index: 200, train loss avg: 2.215170\n",
      "==>>> epoch: 2, batch index: 300, train loss avg: 2.215147\n",
      "==>>> epoch: 2, batch index: 400, train loss avg: 2.214771\n",
      "==>>> epoch: 2, batch index: 500, train loss avg: 2.214969\n",
      "==>>> epoch: 2, batch index: 600, train loss avg: 2.214705\n",
      "==>>> epoch: 2, batch index: 100, test loss: 2.214715, acc: 0.911\n",
      "==>>> epoch: 3, batch index: 100, train loss avg: 2.214349\n",
      "==>>> epoch: 3, batch index: 200, train loss avg: 2.214387\n",
      "==>>> epoch: 3, batch index: 300, train loss avg: 2.214480\n",
      "==>>> epoch: 3, batch index: 400, train loss avg: 2.214363\n",
      "==>>> epoch: 3, batch index: 500, train loss avg: 2.214268\n",
      "==>>> epoch: 3, batch index: 600, train loss avg: 2.214587\n",
      "==>>> epoch: 3, batch index: 100, test loss: 2.214480, acc: 0.918\n",
      "==>>> epoch: 4, batch index: 100, train loss avg: 2.214323\n",
      "==>>> epoch: 4, batch index: 200, train loss avg: 2.214005\n",
      "==>>> epoch: 4, batch index: 300, train loss avg: 2.214119\n",
      "==>>> epoch: 4, batch index: 400, train loss avg: 2.213889\n",
      "==>>> epoch: 4, batch index: 500, train loss avg: 2.213948\n",
      "==>>> epoch: 4, batch index: 600, train loss avg: 2.213984\n",
      "==>>> epoch: 4, batch index: 100, test loss: 2.213916, acc: 0.931\n",
      "==>>> epoch: 5, batch index: 100, train loss avg: 2.213842\n",
      "==>>> epoch: 5, batch index: 200, train loss avg: 2.214261\n",
      "==>>> epoch: 5, batch index: 300, train loss avg: 2.213891\n",
      "==>>> epoch: 5, batch index: 400, train loss avg: 2.213791\n",
      "==>>> epoch: 5, batch index: 500, train loss avg: 2.214108\n",
      "==>>> epoch: 5, batch index: 600, train loss avg: 2.213820\n",
      "==>>> epoch: 5, batch index: 100, test loss: 2.213820, acc: 0.938\n",
      "==>>> epoch: 6, batch index: 100, train loss avg: 2.213787\n",
      "==>>> epoch: 6, batch index: 200, train loss avg: 2.213843\n",
      "==>>> epoch: 6, batch index: 300, train loss avg: 2.213741\n",
      "==>>> epoch: 6, batch index: 400, train loss avg: 2.213717\n",
      "==>>> epoch: 6, batch index: 500, train loss avg: 2.214391\n",
      "==>>> epoch: 6, batch index: 600, train loss avg: 2.213828\n",
      "==>>> epoch: 6, batch index: 100, test loss: 2.213766, acc: 0.941\n",
      "==>>> epoch: 7, batch index: 100, train loss avg: 2.213674\n",
      "==>>> epoch: 7, batch index: 200, train loss avg: 2.213731\n",
      "==>>> epoch: 7, batch index: 300, train loss avg: 2.213709\n",
      "==>>> epoch: 7, batch index: 400, train loss avg: 2.213658\n",
      "==>>> epoch: 7, batch index: 500, train loss avg: 2.213691\n",
      "==>>> epoch: 7, batch index: 600, train loss avg: 2.213749\n",
      "==>>> epoch: 7, batch index: 100, test loss: 2.213626, acc: 0.947\n",
      "==>>> epoch: 8, batch index: 100, train loss avg: 2.213586\n",
      "==>>> epoch: 8, batch index: 200, train loss avg: 2.213527\n",
      "==>>> epoch: 8, batch index: 300, train loss avg: 2.213761\n",
      "==>>> epoch: 8, batch index: 400, train loss avg: 2.213622\n",
      "==>>> epoch: 8, batch index: 500, train loss avg: 2.213661\n",
      "==>>> epoch: 8, batch index: 600, train loss avg: 2.213679\n",
      "==>>> epoch: 8, batch index: 100, test loss: 2.213516, acc: 0.949\n",
      "==>>> epoch: 9, batch index: 100, train loss avg: 2.213548\n",
      "==>>> epoch: 9, batch index: 200, train loss avg: 2.213807\n",
      "==>>> epoch: 9, batch index: 300, train loss avg: 2.213687\n",
      "==>>> epoch: 9, batch index: 400, train loss avg: 2.213653\n",
      "==>>> epoch: 9, batch index: 500, train loss avg: 2.213586\n",
      "==>>> epoch: 9, batch index: 600, train loss avg: 2.213733\n",
      "==>>> epoch: 9, batch index: 100, test loss: 2.213520, acc: 0.950\n"
     ]
    }
   ],
   "source": [
    "global epoch #declear epoch global, to be used later by torch.save() \n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "\n",
    "    ave_loss = 0\n",
    "    global loss #declear loss global, to be used later by torch.save() \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        model.train() #set model to traning mode\n",
    "        optimizer.zero_grad()\n",
    "        data, target = data.float(), target.float() #set datatype\n",
    "        data, target = data.to(device), target.to(device) #transfer to GPU\n",
    "        data, target = Variable(data), Variable(target) #set to pytorch datatype: variable\n",
    "        out = model(data) #forward pass\n",
    "        loss = criterion(out, target.long()) #calculate loss\n",
    "        ave_loss = ave_loss * 0.9 + loss.item() * 0.1 \n",
    "        loss.backward() #back propagation with calculated loss\n",
    "        optimizer.step() #calculate gradient and step\n",
    "        if (batch_idx + 1) % 100 == 0 or (batch_idx + 1) == len(train_loader):\n",
    "            print('==>>> epoch: {}, batch index: {}, train loss avg: {:.6f}'.format(epoch, batch_idx + 1, ave_loss))\n",
    "\n",
    "    correct, ave_loss = 0, 0\n",
    "    total_cnt = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(val_loader):\n",
    "        model.eval() #set model to evaluation mode\n",
    "        data, target = data.float(), target.float() #set datatype\n",
    "        data, target = data.to(device), target.to(device) #transfer to GPU\n",
    "        data, target = Variable(data), Variable(target) #set to pytorch datatype: variable\n",
    "       \n",
    "        out = model(data)\n",
    "        loss = criterion(out, target.long()) #calculate loss\n",
    "\n",
    "        pred_label = out.data\n",
    "        pred_label = pred_label.argmax(dim=1, keepdim=True)\n",
    "        \n",
    "        target = target.long()\n",
    "        target_onehot = one_hot_embedding(target.data, 10)\n",
    "        target_onehot = target_onehot.to(device)\n",
    "        \n",
    "        total_cnt += data.data.size()[0]\n",
    "        ave_loss = ave_loss * 0.9 + loss.item() * 0.1 #smooth average\n",
    "        correct += pred_label.eq(target.view_as(pred_label)).sum().item()\n",
    "        \n",
    "        if (batch_idx + 1) % 100 == 0 or (batch_idx + 1) == len(val_loader):\n",
    "            print(\n",
    "            '==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
    "                epoch, batch_idx + 1, ave_loss, correct * 1.0 / total_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2395018\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
