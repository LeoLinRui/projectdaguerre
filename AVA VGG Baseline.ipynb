{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from skimage import transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "\n",
    "image_dir = r\"C:\\Users\\Leo's PC\\Desktop\\images\"\n",
    "csv_dir = r\"C:\\Users\\Leo's PC\\Desktop\\AVA.txt\"\n",
    "checkpoint_save_dir = r\"C:\\Users\\Leo's PC\\PycharmProjects\\PD\\Model Checkpoints\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dangerous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVA Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AVADataset(Dataset):\n",
    "    \"\"\"AVA dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, file_dir, start, end, class_size=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            file_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            start&end: specify the range in the raw data to construct the dataset from. For spliting calidation and test sets.\n",
    "            class_size = make the amount of images in each rating group equal to class_size.\n",
    "        \"\"\"\n",
    "        self.csv = pd.read_csv(csv_file, sep=' ')\n",
    "        self.file_dir = file_dir\n",
    "        self.transform = transform\n",
    "        self.diction = {}\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.class_size = class_size\n",
    "\n",
    "        for _, _, files in os.walk(self.file_dir): #get a list of file names in the dataset folder\n",
    "            self.img_name_array = files\n",
    "\n",
    "        self.img_name_array = self.img_name_array[start:end] #limit the range of file names to start:end\n",
    "\n",
    "        index = 0\n",
    "        self.rat_distribution = np.zeros(9, dtype=np.int16)\n",
    "        print(\"index =\", index, \"AVA Dataset initialization begin...\")\n",
    "        print(\"Rating distribution initialized: \", self.rat_distribution)\n",
    "        for csv_idx, row in self.csv.iterrows(): #traverse the enitre csv file\n",
    "            image_name = row[1]\n",
    "            if (str(image_name) + '.jpg') in self.img_name_array: \n",
    "                #only add [image_name, avg_rat] to diction when it's in the img_name_array\n",
    "               \n",
    "                rating_array = np.array(row[2:12])\n",
    "                avg_rat = np.argmax(rating_array) + 1\n",
    "                if class_size: #when it's needed to limit class amount\n",
    "                    if self.rat_distribution[avg_rat - 2] < class_size: #only enter if under limit\n",
    "                        self.diction[index] = [image_name, avg_rat] #append\n",
    "                        self.rat_distribution[avg_rat - 2] += 1 #update rat_distribution\n",
    "                        index += 1 #update index\n",
    "                else: #when class amount is not specified. Just append.\n",
    "                    self.diction[index] = [image_name, avg_rat] #append\n",
    "                    index += 1 #update index\n",
    "                if csv_idx % 10000 == 0:\n",
    "                    print('csv_idx:', csv_idx, 'index:', index, 'img_name', image_name, 'avg_rat', avg_rat,\"\\n\",\n",
    "                          \" - Current rating distribution is: \", self.rat_distribution)\n",
    "            \n",
    "        print(\"Stage 1 loading complete. Current rating distribution is: \", self.rat_distribution)\n",
    "\n",
    "        plt.bar(np.arange(9), self.rat_distribution, 0.35) #(indeces, data, width)\n",
    "        plt.ylabel('Number of Pictures')\n",
    "        plt.title('Current Rating Distribution')\n",
    "        plt.xticks(np.arange(9), ('1', '2', '3', '4', '5', '6', '7', '8', '9'))\n",
    "        plt.show()\n",
    "        \n",
    "        #now that all classes are <= class_limit, we need to make all of them = class limit\n",
    "        if class_size: #only proceed when it's needed to limit class amount\n",
    "            self.distribution_multiplier = np.ceil(np.divide(np.full(9, self.class_size), self.rat_distribution))\n",
    "            #np.ceil rounds up to provide enough images in each class. np.fill creates an array with 9 elements = class_size\n",
    "            print(\"Stage 2 begin. Target class size is:\", class_size, \"Distribution multiplier is:\", self.distribution_multiplier)\n",
    "            self.additional_diction = {}\n",
    "            for item in self.diction.items(): #traverse the self.diction\n",
    "                img_name = item[1][0]\n",
    "                avg_rat = item[1][1]\n",
    "                if self.rat_distribution[avg_rat - 2] < class_size: #only enter if < class_limit\n",
    "                    for i in range(int(self.distribution_multiplier[avg_rat - 2])):\n",
    "                        self.additional_diction[len(self.diction) + len(self.additional_diction)] = [image_name, avg_rat]\n",
    "                        #append the same image at the end of additional_diction (distribution_multiplier) times\n",
    "                    self.rat_distribution[avg_rat - 2] += self.distribution_multiplier[avg_rat - 2] #update rat_distribution\n",
    "            self.diction.update(self.additional_diction) #combine diction and additional_diction\n",
    "                    \n",
    "        print(\"AVA Dataset initialization complete. Rating distribution is: \", self.rat_distribution, \"\\n\",\n",
    "        \"contains\", len(self.diction), \"items.\")\n",
    "        \n",
    "        plt.bar(np.arange(9), self.rat_distribution, 0.35) #(indeces, data, width)\n",
    "        plt.ylabel('Number of Pictures')\n",
    "        plt.title('Current Rating Distribution')\n",
    "        plt.xticks(np.arange(9), ('1', '2', '3', '4', '5', '6', '7', '8', '9'))\n",
    "        plt.show()\n",
    "                        \n",
    "                        \n",
    "    def __len__(self):\n",
    "        return len(self.diction)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.diction[idx][0]\n",
    "        rat_avg = self.diction[idx][1]\n",
    "        directory = self.file_dir + \"\\\\\" + str(img_name) + '.jpg'\n",
    "        image = cv2.imread(directory, cv2.IMREAD_COLOR)\n",
    "        sample = {'image': np.array(image, dtype=float), 'rating': np.array(rat_avg, dtype=float)}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions for Dataset Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "     output_size (tuple or int): Desired output size. If tuple, output is\n",
    "         matched to output_size. If int, smaller of image edges is matched\n",
    "         to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, rating = sample['image'], sample['rating']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        return {'image': img, 'rating': rating}\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, rating = sample['image'], sample['rating']\n",
    "        rating = np.array(rating)\n",
    "        image = image.transpose((2, 0, 1)) #swap color axis because: numpy image: H x W x C & torch image: C X H X W\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                 'rating': torch.from_numpy(rating)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset Instances and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index = 0 AVA Dataset initialization begin...\n",
      "Rating distribution initialized:  [0 0 0 0 0 0 0 0 0]\n",
      "csv_idx: 20000 index: 14275 img_name 451851 avg_rat 6 \n",
      "  - Current rating distribution is:  [   4   73 1399 8471 3897  355   42    1   33]\n",
      "csv_idx: 30000 index: 18608 img_name 348334 avg_rat 5 \n",
      "  - Current rating distribution is:  [    5    97  2129 10000  5731   542    51     2    51]\n",
      "csv_idx: 40000 index: 21339 img_name 584770 avg_rat 5 \n",
      "  - Current rating distribution is:  [   10   129  3064 10000  7295   688    75     2    76]\n",
      "csv_idx: 50000 index: 24287 img_name 324746 avg_rat 4 \n",
      "  - Current rating distribution is:  [   11   167  4067 10000  8994   841    98     4   105]\n",
      "csv_idx: 60000 index: 26423 img_name 527494 avg_rat 5 \n",
      "  - Current rating distribution is:  [   14   193  4923 10000 10000  1036   121     5   131]\n",
      "csv_idx: 70000 index: 27383 img_name 682519 avg_rat 6 \n",
      "  - Current rating distribution is:  [   15   215  5582 10000 10000  1267   147     5   152]\n",
      "csv_idx: 80000 index: 28292 img_name 517426 avg_rat 5 \n",
      "  - Current rating distribution is:  [   16   228  6257 10000 10000  1459   166     6   160]\n",
      "csv_idx: 100000 index: 28789 img_name 163900 avg_rat 5 \n",
      "  - Current rating distribution is:  [   16   229  6509 10000 10000  1696   172     6   161]\n",
      "csv_idx: 110000 index: 29799 img_name 44353 avg_rat 5 \n",
      "  - Current rating distribution is:  [   22   269  7212 10000 10000  1920   195     7   174]\n",
      "csv_idx: 130000 index: 31699 img_name 13197 avg_rat 6 \n",
      "  - Current rating distribution is:  [   29   332  8641 10000 10000  2242   236     7   212]\n",
      "csv_idx: 140000 index: 32876 img_name 550282 avg_rat 5 \n",
      "  - Current rating distribution is:  [   34   364  9578 10000 10000  2395   253     9   243]\n",
      "csv_idx: 150000 index: 33563 img_name 292815 avg_rat 5 \n",
      "  - Current rating distribution is:  [   36   398 10000 10000 10000  2577   280    12   260]\n",
      "csv_idx: 160000 index: 33900 img_name 672082 avg_rat 6 \n",
      "  - Current rating distribution is:  [   39   434 10000 10000 10000  2806   321    14   286]\n",
      "csv_idx: 170000 index: 34195 img_name 1906 avg_rat 2 \n",
      "  - Current rating distribution is:  [   49   499 10000 10000 10000  2964   354    15   314]\n",
      "csv_idx: 180000 index: 34442 img_name 115822 avg_rat 4 \n",
      "  - Current rating distribution is:  [   50   518 10000 10000 10000  3145   381    16   332]\n",
      "csv_idx: 190000 index: 34740 img_name 166393 avg_rat 5 \n",
      "  - Current rating distribution is:  [   56   563 10000 10000 10000  3344   410    18   349]\n",
      "csv_idx: 200000 index: 35058 img_name 148639 avg_rat 5 \n",
      "  - Current rating distribution is:  [   60   609 10000 10000 10000  3562   436    18   373]\n",
      "csv_idx: 210000 index: 35331 img_name 678588 avg_rat 5 \n",
      "  - Current rating distribution is:  [   67   663 10000 10000 10000  3745   448    18   390]\n",
      "csv_idx: 250000 index: 36479 img_name 324450 avg_rat 5 \n",
      "  - Current rating distribution is:  [   85   841 10000 10000 10000  4519   536    20   478]\n",
      "Stage 1 loading complete. Current rating distribution is:  [   89   853 10000 10000 10000  4626   549    21   499]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 begin. Target class size is: 10000 Distribution multiplier is: [113.  12.   1.   1.   1.   3.  19. 477.  21.]\n",
      "AVA Dataset initialization complete. Rating distribution is:  [10033 10009 10000 10000 10000 10002 10011 10038 10012] \n",
      " contains 90105 items.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index = 0 AVA Dataset initialization begin...\n",
      "Rating distribution initialized:  [0 0 0 0 0 0 0 0 0]\n",
      "csv_idx: 10000 index: 2295 img_name 758229 avg_rat 5 \n",
      "  - Current rating distribution is:  [   0   10  182 1314  721   61    6    0    1]\n",
      "csv_idx: 90000 index: 7608 img_name 776483 avg_rat 5 \n",
      "  - Current rating distribution is:  [   4   44 1057 3000 3000  446   32    1   24]\n",
      "csv_idx: 120000 index: 8351 img_name 814905 avg_rat 6 \n",
      "  - Current rating distribution is:  [   4   58 1459 3000 3000  757   43    1   29]\n",
      "csv_idx: 220000 index: 10387 img_name 807308 avg_rat 5 \n",
      "  - Current rating distribution is:  [   9  130 2828 3000 3000 1233   95    7   85]\n",
      "csv_idx: 230000 index: 10633 img_name 814300 avg_rat 5 \n",
      "  - Current rating distribution is:  [  13  143 3000 3000 3000 1278  100    7   92]\n",
      "Stage 1 loading complete. Current rating distribution is:  [  13  160 3000 3000 3000 1398  107    7   96]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 begin. Target class size is: 3000 Distribution multiplier is: [231.  19.   1.   1.   1.   3.  29. 429.  32.]\n",
      "AVA Dataset initialization complete. Rating distribution is:  [3016 3010 3000 3000 3000 3000 3007 3010 3008] \n",
      " contains 27051 items.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "AVA_Train = AVADataset(csv_file=csv_dir, file_dir=image_dir, start=0, end=179999, class_size=10000, transform=transforms.Compose([Rescale((224, 224)), ToTensor()]))\n",
    "AVA_Validation = AVADataset(csv_file=csv_dir, file_dir=image_dir, start=180000, end=229999, class_size=3000, transform=transforms.Compose([Rescale((224, 224)), ToTensor()]))\n",
    "# AVA_Test = AVADataset(csv_file=csv_dir, file_dir=image_dir, start=230000, end=249999, transform=transforms.Compose([Rescale((224, 224)), ToTensor()]))\n",
    "\n",
    "train_loader = DataLoader(dataset=AVA_Train, batch_size=2,shuffle=True)\n",
    "val_loader = DataLoader(dataset=AVA_Validation, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pretrained Models for Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "VGG = torchvision.models.vgg19_bn(pretrained=True)\n",
    "VGG.classifier._modules['0'] = nn.Linear(25088, 4096)\n",
    "VGG.classifier._modules['3'] = nn.Linear(4096, 4096)\n",
    "VGG.classifier._modules['6'] = nn.Linear(4096, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LeoNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeoNet, self).__init__()\n",
    "        self.VGG = VGG  # input shape is 224*224*3\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = VGG(x)\n",
    "        return x\n",
    "\n",
    "    def name(self):\n",
    "        return \"LeoNet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeoNet(\n",
      "  (VGG): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (12): ReLU(inplace=True)\n",
      "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (16): ReLU(inplace=True)\n",
      "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (19): ReLU(inplace=True)\n",
      "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (32): ReLU(inplace=True)\n",
      "      (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (35): ReLU(inplace=True)\n",
      "      (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (38): ReLU(inplace=True)\n",
      "      (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (42): ReLU(inplace=True)\n",
      "      (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (45): ReLU(inplace=True)\n",
      "      (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (48): ReLU(inplace=True)\n",
      "      (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (51): ReLU(inplace=True)\n",
      "      (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LeoNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization for single-GPU/CPU training ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LeoNet(\n",
       "  (VGG): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): ReLU(inplace=True)\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU(inplace=True)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): ReLU(inplace=True)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (32): ReLU(inplace=True)\n",
       "      (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (35): ReLU(inplace=True)\n",
       "      (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (38): ReLU(inplace=True)\n",
       "      (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (42): ReLU(inplace=True)\n",
       "      (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (45): ReLU(inplace=True)\n",
       "      (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (48): ReLU(inplace=True)\n",
       "      (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (51): ReLU(inplace=True)\n",
       "      (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 0, batch index: 1000, train loss: 4.669499\n",
      "==>>> epoch: 0, batch index: 2000, train loss: 7.333076\n",
      "==>>> epoch: 0, batch index: 3000, train loss: 10.752376\n",
      "==>>> epoch: 0, batch index: 4000, train loss: 0.788775\n",
      "==>>> epoch: 0, batch index: 5000, train loss: 1.881124\n",
      "==>>> epoch: 0, batch index: 6000, train loss: 1.543768\n",
      "==>>> epoch: 0, batch index: 7000, train loss: 16.722252\n",
      "==>>> epoch: 0, batch index: 8000, train loss: 1.545300\n",
      "==>>> epoch: 0, batch index: 9000, train loss: 6.969606\n",
      "==>>> epoch: 0, batch index: 10000, train loss: 9.179030\n",
      "==>>> epoch: 0, batch index: 11000, train loss: 7.843976\n",
      "==>>> epoch: 0, batch index: 12000, train loss: 1.103102\n",
      "==>>> epoch: 0, batch index: 13000, train loss: 13.015014\n",
      "==>>> epoch: 0, batch index: 14000, train loss: 6.658174\n",
      "==>>> epoch: 0, batch index: 15000, train loss: 3.136650\n",
      "==>>> epoch: 0, batch index: 16000, train loss: 2.109450\n",
      "==>>> epoch: 0, batch index: 17000, train loss: 8.741089\n",
      "==>>> epoch: 0, batch index: 18000, train loss: 12.057253\n",
      "==>>> epoch: 0, batch index: 19000, train loss: 5.641551\n",
      "==>>> epoch: 0, batch index: 20000, train loss: 5.325882\n",
      "==>>> epoch: 0, batch index: 21000, train loss: 5.421195\n",
      "==>>> epoch: 0, batch index: 22000, train loss: 5.049000\n",
      "==>>> epoch: 0, batch index: 23000, train loss: 9.912780\n",
      "==>>> epoch: 0, batch index: 24000, train loss: 0.273239\n",
      "==>>> epoch: 0, batch index: 25000, train loss: 3.994312\n",
      "==>>> epoch: 0, batch index: 26000, train loss: 1.022689\n",
      "==>>> epoch: 0, batch index: 27000, train loss: 4.575288\n",
      "==>>> epoch: 0, batch index: 28000, train loss: 0.389437\n",
      "==>>> epoch: 0, batch index: 29000, train loss: 10.529606\n",
      "==>>> epoch: 0, batch index: 30000, train loss: 7.303706\n",
      "==>>> epoch: 0, batch index: 31000, train loss: 7.537917\n",
      "==>>> epoch: 0, batch index: 32000, train loss: 5.513984\n",
      "==>>> epoch: 0, batch index: 33000, train loss: 1.948389\n",
      "==>>> epoch: 0, batch index: 34000, train loss: 1.309535\n",
      "==>>> epoch: 0, batch index: 35000, train loss: 7.732298\n",
      "==>>> epoch: 0, batch index: 36000, train loss: 7.488499\n",
      "==>>> epoch: 0, batch index: 37000, train loss: 14.277234\n",
      "==>>> epoch: 0, batch index: 38000, train loss: 7.835269\n",
      "==>>> epoch: 0, batch index: 39000, train loss: 2.679874\n",
      "==>>> epoch: 0, batch index: 40000, train loss: 0.391488\n",
      "==>>> epoch: 0, batch index: 41000, train loss: 5.795460\n",
      "==>>> epoch: 0, batch index: 42000, train loss: 3.787086\n",
      "==>>> epoch: 0, batch index: 43000, train loss: 5.666354\n",
      "==>>> epoch: 0, batch index: 44000, train loss: 6.138141\n",
      "==>>> epoch: 0, batch index: 45000, train loss: 21.466400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\loss.py:432: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 0, batch index: 45053, train loss: 4.725105\n",
      "==>>> epoch: 0, batch index: 1000, test loss: 0.737510, acc: 0.818\n",
      "tensor([5., 5.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 0, batch index: 2000, test loss: 0.657841, acc: 0.845\n",
      "tensor([4., 5.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 0, batch index: 3000, test loss: 0.806808, acc: 0.802\n",
      "tensor([4., 5.], device='cuda:0') tensor([[6.],\n",
      "        [6.]], device='cuda:0')\n",
      "==>>> epoch: 0, batch index: 4000, test loss: 2.103366, acc: 0.724\n",
      "tensor([4., 5.], device='cuda:0') tensor([[4.],\n",
      "        [4.]], device='cuda:0')\n",
      "==>>> epoch: 0, batch index: 5000, test loss: 4.630933, acc: 0.703\n",
      "tensor([6., 7.], device='cuda:0') tensor([[4.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 0, batch index: 6000, test loss: 4.314698, acc: 0.618\n",
      "tensor([4., 4.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 0, batch index: 7000, test loss: 4.145288, acc: 0.529\n",
      "tensor([4., 4.], device='cuda:0') tensor([[3.],\n",
      "        [3.]], device='cuda:0')\n",
      "==>>> epoch: 0, batch index: 8000, test loss: 7.552876, acc: 0.463\n",
      "tensor([4., 4.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 0, batch index: 9000, test loss: 8.563629, acc: 0.412\n",
      "tensor([4., 4.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 0, batch index: 10000, test loss: 16.576952, acc: 0.371\n",
      "tensor([4., 4.], device='cuda:0') tensor([[9.],\n",
      "        [9.]], device='cuda:0')\n",
      "==>>> epoch: 0, batch index: 11000, test loss: 14.764666, acc: 0.337\n",
      "tensor([4., 4.], device='cuda:0') tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 0, batch index: 12000, test loss: 9.853325, acc: 0.309\n",
      "tensor([4., 4.], device='cuda:0') tensor([[8.],\n",
      "        [8.]], device='cuda:0')\n",
      "==>>> epoch: 0, batch index: 13000, test loss: 8.535670, acc: 0.285\n",
      "tensor([4., 4.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 0, batch index: 13526, test loss: 4.729393, acc: 0.274\n",
      "tensor([4., 3.], device='cuda:0') tensor([[3.],\n",
      "        [0.]], device='cuda:0')\n",
      "==>>> epoch: 1, batch index: 1000, train loss: 0.801193\n",
      "==>>> epoch: 1, batch index: 2000, train loss: 5.032944\n",
      "==>>> epoch: 1, batch index: 3000, train loss: 0.909393\n",
      "==>>> epoch: 1, batch index: 4000, train loss: 4.951738\n",
      "==>>> epoch: 1, batch index: 5000, train loss: 12.653948\n",
      "==>>> epoch: 1, batch index: 6000, train loss: 5.971434\n",
      "==>>> epoch: 1, batch index: 7000, train loss: 1.115398\n",
      "==>>> epoch: 1, batch index: 8000, train loss: 1.821790\n",
      "==>>> epoch: 1, batch index: 9000, train loss: 5.914430\n",
      "==>>> epoch: 1, batch index: 10000, train loss: 14.425896\n",
      "==>>> epoch: 1, batch index: 11000, train loss: 7.398337\n",
      "==>>> epoch: 1, batch index: 12000, train loss: 7.050484\n",
      "==>>> epoch: 1, batch index: 13000, train loss: 9.351643\n",
      "==>>> epoch: 1, batch index: 14000, train loss: 0.758435\n",
      "==>>> epoch: 1, batch index: 15000, train loss: 4.270294\n",
      "==>>> epoch: 1, batch index: 16000, train loss: 0.631284\n",
      "==>>> epoch: 1, batch index: 17000, train loss: 4.933462\n",
      "==>>> epoch: 1, batch index: 18000, train loss: 3.942612\n",
      "==>>> epoch: 1, batch index: 19000, train loss: 8.949110\n",
      "==>>> epoch: 1, batch index: 20000, train loss: 1.949050\n",
      "==>>> epoch: 1, batch index: 21000, train loss: 9.768564\n",
      "==>>> epoch: 1, batch index: 22000, train loss: 5.788417\n",
      "==>>> epoch: 1, batch index: 23000, train loss: 1.834892\n",
      "==>>> epoch: 1, batch index: 24000, train loss: 0.928390\n",
      "==>>> epoch: 1, batch index: 25000, train loss: 9.940876\n",
      "==>>> epoch: 1, batch index: 26000, train loss: 4.225759\n",
      "==>>> epoch: 1, batch index: 27000, train loss: 3.648316\n",
      "==>>> epoch: 1, batch index: 28000, train loss: 1.861814\n",
      "==>>> epoch: 1, batch index: 29000, train loss: 12.960581\n",
      "==>>> epoch: 1, batch index: 30000, train loss: 1.020652\n",
      "==>>> epoch: 1, batch index: 31000, train loss: 6.739229\n",
      "==>>> epoch: 1, batch index: 32000, train loss: 8.737556\n",
      "==>>> epoch: 1, batch index: 33000, train loss: 15.311247\n",
      "==>>> epoch: 1, batch index: 34000, train loss: 0.768783\n",
      "==>>> epoch: 1, batch index: 35000, train loss: 0.649383\n",
      "==>>> epoch: 1, batch index: 36000, train loss: 6.318865\n",
      "==>>> epoch: 1, batch index: 37000, train loss: 10.832705\n",
      "==>>> epoch: 1, batch index: 38000, train loss: 6.006608\n",
      "==>>> epoch: 1, batch index: 39000, train loss: 8.558976\n",
      "==>>> epoch: 1, batch index: 40000, train loss: 13.491908\n",
      "==>>> epoch: 1, batch index: 41000, train loss: 13.793526\n",
      "==>>> epoch: 1, batch index: 42000, train loss: 1.662826\n",
      "==>>> epoch: 1, batch index: 43000, train loss: 13.358925\n",
      "==>>> epoch: 1, batch index: 44000, train loss: 8.985579\n",
      "==>>> epoch: 1, batch index: 45000, train loss: 2.725370\n",
      "==>>> epoch: 1, batch index: 45053, train loss: 2.045138\n",
      "==>>> epoch: 1, batch index: 1000, test loss: 0.636766, acc: 0.745\n",
      "tensor([5., 5.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 1, batch index: 2000, test loss: 0.522266, acc: 0.791\n",
      "tensor([5., 4.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 1, batch index: 3000, test loss: 0.719126, acc: 0.779\n",
      "tensor([5., 6.], device='cuda:0') tensor([[6.],\n",
      "        [6.]], device='cuda:0')\n",
      "==>>> epoch: 1, batch index: 4000, test loss: 1.810822, acc: 0.725\n",
      "tensor([4., 5.], device='cuda:0') tensor([[4.],\n",
      "        [4.]], device='cuda:0')\n",
      "==>>> epoch: 1, batch index: 5000, test loss: 3.454733, acc: 0.730\n",
      "tensor([6., 5.], device='cuda:0') tensor([[4.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 1, batch index: 6000, test loss: 3.969623, acc: 0.648\n",
      "tensor([5., 5.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 1, batch index: 7000, test loss: 4.209023, acc: 0.556\n",
      "tensor([5., 5.], device='cuda:0') tensor([[3.],\n",
      "        [3.]], device='cuda:0')\n",
      "==>>> epoch: 1, batch index: 8000, test loss: 7.133930, acc: 0.486\n",
      "tensor([5., 5.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 1, batch index: 9000, test loss: 9.046041, acc: 0.432\n",
      "tensor([5., 5.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 1, batch index: 10000, test loss: 15.896048, acc: 0.389\n",
      "tensor([5., 5.], device='cuda:0') tensor([[9.],\n",
      "        [9.]], device='cuda:0')\n",
      "==>>> epoch: 1, batch index: 11000, test loss: 15.337514, acc: 0.354\n",
      "tensor([5., 5.], device='cuda:0') tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 1, batch index: 12000, test loss: 9.419078, acc: 0.324\n",
      "tensor([5., 5.], device='cuda:0') tensor([[8.],\n",
      "        [8.]], device='cuda:0')\n",
      "==>>> epoch: 1, batch index: 13000, test loss: 9.038364, acc: 0.299\n",
      "tensor([5., 5.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 1, batch index: 13526, test loss: 5.087676, acc: 0.288\n",
      "tensor([5., 3.], device='cuda:0') tensor([[3.],\n",
      "        [0.]], device='cuda:0')\n",
      "==>>> epoch: 2, batch index: 1000, train loss: 11.607208\n",
      "==>>> epoch: 2, batch index: 2000, train loss: 12.658390\n",
      "==>>> epoch: 2, batch index: 3000, train loss: 6.359931\n",
      "==>>> epoch: 2, batch index: 4000, train loss: 7.384467\n",
      "==>>> epoch: 2, batch index: 5000, train loss: 0.420280\n",
      "==>>> epoch: 2, batch index: 6000, train loss: 9.057851\n",
      "==>>> epoch: 2, batch index: 7000, train loss: 12.717370\n",
      "==>>> epoch: 2, batch index: 8000, train loss: 3.969818\n",
      "==>>> epoch: 2, batch index: 9000, train loss: 0.753182\n",
      "==>>> epoch: 2, batch index: 10000, train loss: 0.106217\n",
      "==>>> epoch: 2, batch index: 11000, train loss: 1.581316\n",
      "==>>> epoch: 2, batch index: 12000, train loss: 10.619302\n",
      "==>>> epoch: 2, batch index: 13000, train loss: 13.406721\n",
      "==>>> epoch: 2, batch index: 14000, train loss: 2.155125\n",
      "==>>> epoch: 2, batch index: 15000, train loss: 11.420543\n",
      "==>>> epoch: 2, batch index: 16000, train loss: 6.327013\n",
      "==>>> epoch: 2, batch index: 17000, train loss: 9.029535\n",
      "==>>> epoch: 2, batch index: 18000, train loss: 3.680748\n",
      "==>>> epoch: 2, batch index: 19000, train loss: 12.548353\n",
      "==>>> epoch: 2, batch index: 20000, train loss: 4.375944\n",
      "==>>> epoch: 2, batch index: 21000, train loss: 10.084002\n",
      "==>>> epoch: 2, batch index: 22000, train loss: 7.740855\n",
      "==>>> epoch: 2, batch index: 23000, train loss: 0.864797\n",
      "==>>> epoch: 2, batch index: 24000, train loss: 6.418499\n",
      "==>>> epoch: 2, batch index: 25000, train loss: 5.264336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 2, batch index: 26000, train loss: 8.859892\n",
      "==>>> epoch: 2, batch index: 27000, train loss: 4.799541\n",
      "==>>> epoch: 2, batch index: 28000, train loss: 7.097206\n",
      "==>>> epoch: 2, batch index: 29000, train loss: 10.186281\n",
      "==>>> epoch: 2, batch index: 30000, train loss: 8.049887\n",
      "==>>> epoch: 2, batch index: 31000, train loss: 1.263427\n",
      "==>>> epoch: 2, batch index: 32000, train loss: 10.985079\n",
      "==>>> epoch: 2, batch index: 33000, train loss: 4.648409\n",
      "==>>> epoch: 2, batch index: 34000, train loss: 6.231001\n",
      "==>>> epoch: 2, batch index: 35000, train loss: 7.158130\n",
      "==>>> epoch: 2, batch index: 36000, train loss: 7.733141\n",
      "==>>> epoch: 2, batch index: 37000, train loss: 6.889097\n",
      "==>>> epoch: 2, batch index: 38000, train loss: 0.122411\n",
      "==>>> epoch: 2, batch index: 39000, train loss: 3.279079\n",
      "==>>> epoch: 2, batch index: 40000, train loss: 5.338599\n",
      "==>>> epoch: 2, batch index: 41000, train loss: 0.484247\n",
      "==>>> epoch: 2, batch index: 42000, train loss: 6.413973\n",
      "==>>> epoch: 2, batch index: 43000, train loss: 8.195911\n",
      "==>>> epoch: 2, batch index: 44000, train loss: 4.346689\n",
      "==>>> epoch: 2, batch index: 45000, train loss: 8.159829\n",
      "==>>> epoch: 2, batch index: 45053, train loss: 14.110203\n",
      "==>>> epoch: 2, batch index: 1000, test loss: 0.750132, acc: 0.912\n",
      "tensor([5., 5.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 2, batch index: 2000, test loss: 0.630112, acc: 0.960\n",
      "tensor([5., 4.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 2, batch index: 3000, test loss: 0.680475, acc: 0.885\n",
      "tensor([5., 6.], device='cuda:0') tensor([[6.],\n",
      "        [6.]], device='cuda:0')\n",
      "==>>> epoch: 2, batch index: 4000, test loss: 1.755525, acc: 0.769\n",
      "tensor([4., 5.], device='cuda:0') tensor([[4.],\n",
      "        [4.]], device='cuda:0')\n",
      "==>>> epoch: 2, batch index: 5000, test loss: 3.250227, acc: 0.721\n",
      "tensor([6., 5.], device='cuda:0') tensor([[4.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 2, batch index: 6000, test loss: 4.152583, acc: 0.630\n",
      "tensor([4., 4.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 2, batch index: 7000, test loss: 4.173111, acc: 0.540\n",
      "tensor([4., 4.], device='cuda:0') tensor([[3.],\n",
      "        [3.]], device='cuda:0')\n",
      "==>>> epoch: 2, batch index: 8000, test loss: 7.356440, acc: 0.473\n",
      "tensor([4., 4.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 2, batch index: 9000, test loss: 8.785974, acc: 0.420\n",
      "tensor([4., 4.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 2, batch index: 10000, test loss: 16.258809, acc: 0.378\n",
      "tensor([4., 4.], device='cuda:0') tensor([[9.],\n",
      "        [9.]], device='cuda:0')\n",
      "==>>> epoch: 2, batch index: 11000, test loss: 15.029028, acc: 0.344\n",
      "tensor([4., 4.], device='cuda:0') tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 2, batch index: 12000, test loss: 9.649780, acc: 0.315\n",
      "tensor([4., 4.], device='cuda:0') tensor([[8.],\n",
      "        [8.]], device='cuda:0')\n",
      "==>>> epoch: 2, batch index: 13000, test loss: 8.767438, acc: 0.291\n",
      "tensor([4., 4.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 2, batch index: 13526, test loss: 4.894066, acc: 0.280\n",
      "tensor([4., 3.], device='cuda:0') tensor([[3.],\n",
      "        [0.]], device='cuda:0')\n",
      "==>>> epoch: 3, batch index: 1000, train loss: 11.254072\n",
      "==>>> epoch: 3, batch index: 2000, train loss: 20.838802\n",
      "==>>> epoch: 3, batch index: 3000, train loss: 3.603905\n",
      "==>>> epoch: 3, batch index: 4000, train loss: 17.188095\n",
      "==>>> epoch: 3, batch index: 5000, train loss: 6.649985\n",
      "==>>> epoch: 3, batch index: 6000, train loss: 3.160941\n",
      "==>>> epoch: 3, batch index: 7000, train loss: 2.191467\n",
      "==>>> epoch: 3, batch index: 8000, train loss: 7.703394\n",
      "==>>> epoch: 3, batch index: 9000, train loss: 1.930785\n",
      "==>>> epoch: 3, batch index: 10000, train loss: 11.190770\n",
      "==>>> epoch: 3, batch index: 11000, train loss: 9.016430\n",
      "==>>> epoch: 3, batch index: 12000, train loss: 2.946785\n",
      "==>>> epoch: 3, batch index: 13000, train loss: 0.598985\n",
      "==>>> epoch: 3, batch index: 14000, train loss: 7.659798\n",
      "==>>> epoch: 3, batch index: 15000, train loss: 8.737118\n",
      "==>>> epoch: 3, batch index: 16000, train loss: 7.596583\n",
      "==>>> epoch: 3, batch index: 17000, train loss: 8.087410\n",
      "==>>> epoch: 3, batch index: 18000, train loss: 9.544305\n",
      "==>>> epoch: 3, batch index: 19000, train loss: 15.818325\n",
      "==>>> epoch: 3, batch index: 20000, train loss: 6.707455\n",
      "==>>> epoch: 3, batch index: 21000, train loss: 3.393996\n",
      "==>>> epoch: 3, batch index: 22000, train loss: 9.219675\n",
      "==>>> epoch: 3, batch index: 23000, train loss: 14.249850\n",
      "==>>> epoch: 3, batch index: 24000, train loss: 3.411932\n",
      "==>>> epoch: 3, batch index: 25000, train loss: 6.180877\n",
      "==>>> epoch: 3, batch index: 26000, train loss: 0.818214\n",
      "==>>> epoch: 3, batch index: 27000, train loss: 0.037008\n",
      "==>>> epoch: 3, batch index: 28000, train loss: 6.704356\n",
      "==>>> epoch: 3, batch index: 29000, train loss: 11.322733\n",
      "==>>> epoch: 3, batch index: 30000, train loss: 4.209813\n",
      "==>>> epoch: 3, batch index: 31000, train loss: 5.312011\n",
      "==>>> epoch: 3, batch index: 32000, train loss: 12.387072\n",
      "==>>> epoch: 3, batch index: 33000, train loss: 5.028283\n",
      "==>>> epoch: 3, batch index: 34000, train loss: 1.318829\n",
      "==>>> epoch: 3, batch index: 35000, train loss: 10.033964\n",
      "==>>> epoch: 3, batch index: 36000, train loss: 9.134233\n",
      "==>>> epoch: 3, batch index: 37000, train loss: 10.467196\n",
      "==>>> epoch: 3, batch index: 38000, train loss: 3.487277\n",
      "==>>> epoch: 3, batch index: 39000, train loss: 0.137233\n",
      "==>>> epoch: 3, batch index: 40000, train loss: 0.059947\n",
      "==>>> epoch: 3, batch index: 41000, train loss: 22.247721\n",
      "==>>> epoch: 3, batch index: 42000, train loss: 10.531635\n",
      "==>>> epoch: 3, batch index: 43000, train loss: 6.252605\n",
      "==>>> epoch: 3, batch index: 44000, train loss: 9.530031\n",
      "==>>> epoch: 3, batch index: 45000, train loss: 9.348433\n",
      "==>>> epoch: 3, batch index: 45053, train loss: 14.331034\n",
      "==>>> epoch: 3, batch index: 1000, test loss: 0.700267, acc: 0.843\n",
      "tensor([5., 5.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 3, batch index: 2000, test loss: 0.688734, acc: 0.879\n",
      "tensor([5., 4.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 3, batch index: 3000, test loss: 0.852688, acc: 0.860\n",
      "tensor([4., 6.], device='cuda:0') tensor([[6.],\n",
      "        [6.]], device='cuda:0')\n",
      "==>>> epoch: 3, batch index: 4000, test loss: 1.873919, acc: 0.774\n",
      "tensor([4., 5.], device='cuda:0') tensor([[4.],\n",
      "        [4.]], device='cuda:0')\n",
      "==>>> epoch: 3, batch index: 5000, test loss: 3.527736, acc: 0.744\n",
      "tensor([6., 5.], device='cuda:0') tensor([[4.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 3, batch index: 6000, test loss: 3.933114, acc: 0.651\n",
      "tensor([5., 5.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 3, batch index: 7000, test loss: 4.216790, acc: 0.558\n",
      "tensor([5., 5.], device='cuda:0') tensor([[3.],\n",
      "        [3.]], device='cuda:0')\n",
      "==>>> epoch: 3, batch index: 8000, test loss: 7.089421, acc: 0.488\n",
      "tensor([5., 5.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 3, batch index: 9000, test loss: 9.099150, acc: 0.434\n",
      "tensor([5., 5.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 3, batch index: 10000, test loss: 15.823169, acc: 0.391\n",
      "tensor([5., 5.], device='cuda:0') tensor([[9.],\n",
      "        [9.]], device='cuda:0')\n",
      "==>>> epoch: 3, batch index: 11000, test loss: 15.400417, acc: 0.355\n",
      "tensor([5., 5.], device='cuda:0') tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 3, batch index: 12000, test loss: 9.372911, acc: 0.326\n",
      "tensor([5., 5.], device='cuda:0') tensor([[8.],\n",
      "        [8.]], device='cuda:0')\n",
      "==>>> epoch: 3, batch index: 13000, test loss: 9.093670, acc: 0.300\n",
      "tensor([5., 5.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 3, batch index: 13526, test loss: 5.127342, acc: 0.289\n",
      "tensor([5., 3.], device='cuda:0') tensor([[3.],\n",
      "        [0.]], device='cuda:0')\n",
      "==>>> epoch: 4, batch index: 1000, train loss: 7.958393\n",
      "==>>> epoch: 4, batch index: 2000, train loss: 8.575927\n",
      "==>>> epoch: 4, batch index: 3000, train loss: 5.148259\n",
      "==>>> epoch: 4, batch index: 4000, train loss: 5.837667\n",
      "==>>> epoch: 4, batch index: 5000, train loss: 7.360497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 4, batch index: 6000, train loss: 6.271185\n",
      "==>>> epoch: 4, batch index: 7000, train loss: 7.766613\n",
      "==>>> epoch: 4, batch index: 8000, train loss: 10.515640\n",
      "==>>> epoch: 4, batch index: 9000, train loss: 2.349943\n",
      "==>>> epoch: 4, batch index: 10000, train loss: 3.919986\n",
      "==>>> epoch: 4, batch index: 11000, train loss: 3.663414\n",
      "==>>> epoch: 4, batch index: 12000, train loss: 6.880255\n",
      "==>>> epoch: 4, batch index: 13000, train loss: 10.638359\n",
      "==>>> epoch: 4, batch index: 14000, train loss: 11.701506\n",
      "==>>> epoch: 4, batch index: 15000, train loss: 7.237462\n",
      "==>>> epoch: 4, batch index: 16000, train loss: 3.385210\n",
      "==>>> epoch: 4, batch index: 17000, train loss: 1.361278\n",
      "==>>> epoch: 4, batch index: 18000, train loss: 7.757658\n",
      "==>>> epoch: 4, batch index: 19000, train loss: 11.633323\n",
      "==>>> epoch: 4, batch index: 20000, train loss: 12.915934\n",
      "==>>> epoch: 4, batch index: 21000, train loss: 5.029591\n",
      "==>>> epoch: 4, batch index: 22000, train loss: 10.509087\n",
      "==>>> epoch: 4, batch index: 23000, train loss: 8.480681\n",
      "==>>> epoch: 4, batch index: 24000, train loss: 11.359453\n",
      "==>>> epoch: 4, batch index: 25000, train loss: 4.390481\n",
      "==>>> epoch: 4, batch index: 26000, train loss: 10.381077\n",
      "==>>> epoch: 4, batch index: 27000, train loss: 17.010586\n",
      "==>>> epoch: 4, batch index: 28000, train loss: 12.474815\n",
      "==>>> epoch: 4, batch index: 29000, train loss: 5.279759\n",
      "==>>> epoch: 4, batch index: 30000, train loss: 11.724470\n",
      "==>>> epoch: 4, batch index: 31000, train loss: 3.914110\n",
      "==>>> epoch: 4, batch index: 32000, train loss: 4.158268\n",
      "==>>> epoch: 4, batch index: 33000, train loss: 11.876434\n",
      "==>>> epoch: 4, batch index: 34000, train loss: 9.063770\n",
      "==>>> epoch: 4, batch index: 35000, train loss: 7.469284\n",
      "==>>> epoch: 4, batch index: 36000, train loss: 4.766024\n",
      "==>>> epoch: 4, batch index: 37000, train loss: 16.815514\n",
      "==>>> epoch: 4, batch index: 38000, train loss: 7.631734\n",
      "==>>> epoch: 4, batch index: 39000, train loss: 2.183059\n",
      "==>>> epoch: 4, batch index: 40000, train loss: 2.391945\n",
      "==>>> epoch: 4, batch index: 41000, train loss: 5.103502\n",
      "==>>> epoch: 4, batch index: 42000, train loss: 1.313806\n",
      "==>>> epoch: 4, batch index: 43000, train loss: 8.726790\n",
      "==>>> epoch: 4, batch index: 44000, train loss: 7.316996\n",
      "==>>> epoch: 4, batch index: 45000, train loss: 1.955810\n",
      "==>>> epoch: 4, batch index: 45053, train loss: 7.092545\n",
      "==>>> epoch: 4, batch index: 1000, test loss: 1.015155, acc: 0.707\n",
      "tensor([6., 5.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 4, batch index: 2000, test loss: 0.900461, acc: 0.733\n",
      "tensor([5., 5.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 4, batch index: 3000, test loss: 0.844519, acc: 0.730\n",
      "tensor([5., 6.], device='cuda:0') tensor([[6.],\n",
      "        [6.]], device='cuda:0')\n",
      "==>>> epoch: 4, batch index: 4000, test loss: 1.521012, acc: 0.703\n",
      "tensor([4., 5.], device='cuda:0') tensor([[4.],\n",
      "        [4.]], device='cuda:0')\n",
      "==>>> epoch: 4, batch index: 5000, test loss: 3.334381, acc: 0.710\n",
      "tensor([6., 5.], device='cuda:0') tensor([[4.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 4, batch index: 6000, test loss: 4.739051, acc: 0.634\n",
      "tensor([4., 4.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 4, batch index: 7000, test loss: 4.088727, acc: 0.544\n",
      "tensor([4., 4.], device='cuda:0') tensor([[3.],\n",
      "        [3.]], device='cuda:0')\n",
      "==>>> epoch: 4, batch index: 8000, test loss: 8.064129, acc: 0.476\n",
      "tensor([4., 4.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 4, batch index: 9000, test loss: 8.014550, acc: 0.423\n",
      "tensor([4., 4.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 4, batch index: 10000, test loss: 17.396370, acc: 0.381\n",
      "tensor([4., 4.], device='cuda:0') tensor([[9.],\n",
      "        [9.]], device='cuda:0')\n",
      "==>>> epoch: 4, batch index: 11000, test loss: 14.109198, acc: 0.346\n",
      "tensor([4., 4.], device='cuda:0') tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 4, batch index: 12000, test loss: 10.382580, acc: 0.317\n",
      "tensor([4., 4.], device='cuda:0') tensor([[8.],\n",
      "        [8.]], device='cuda:0')\n",
      "==>>> epoch: 4, batch index: 13000, test loss: 7.962731, acc: 0.293\n",
      "tensor([4., 4.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 4, batch index: 13526, test loss: 4.326333, acc: 0.281\n",
      "tensor([4., 3.], device='cuda:0') tensor([[3.],\n",
      "        [0.]], device='cuda:0')\n",
      "==>>> epoch: 5, batch index: 1000, train loss: 16.950687\n",
      "==>>> epoch: 5, batch index: 2000, train loss: 14.653771\n",
      "==>>> epoch: 5, batch index: 3000, train loss: 10.344549\n",
      "==>>> epoch: 5, batch index: 4000, train loss: 3.510190\n",
      "==>>> epoch: 5, batch index: 5000, train loss: 3.896454\n",
      "==>>> epoch: 5, batch index: 6000, train loss: 7.059307\n",
      "==>>> epoch: 5, batch index: 7000, train loss: 5.198684\n",
      "==>>> epoch: 5, batch index: 8000, train loss: 7.389968\n",
      "==>>> epoch: 5, batch index: 9000, train loss: 4.619524\n",
      "==>>> epoch: 5, batch index: 10000, train loss: 3.846587\n",
      "==>>> epoch: 5, batch index: 11000, train loss: 6.552055\n",
      "==>>> epoch: 5, batch index: 12000, train loss: 2.357352\n",
      "==>>> epoch: 5, batch index: 13000, train loss: 15.462404\n",
      "==>>> epoch: 5, batch index: 14000, train loss: 15.868362\n",
      "==>>> epoch: 5, batch index: 15000, train loss: 4.611814\n",
      "==>>> epoch: 5, batch index: 16000, train loss: 0.711513\n",
      "==>>> epoch: 5, batch index: 17000, train loss: 9.992701\n",
      "==>>> epoch: 5, batch index: 18000, train loss: 1.360225\n",
      "==>>> epoch: 5, batch index: 19000, train loss: 10.987335\n",
      "==>>> epoch: 5, batch index: 20000, train loss: 13.359526\n",
      "==>>> epoch: 5, batch index: 21000, train loss: 3.940971\n",
      "==>>> epoch: 5, batch index: 22000, train loss: 9.088852\n",
      "==>>> epoch: 5, batch index: 23000, train loss: 10.801023\n",
      "==>>> epoch: 5, batch index: 24000, train loss: 19.973885\n",
      "==>>> epoch: 5, batch index: 25000, train loss: 3.278321\n",
      "==>>> epoch: 5, batch index: 26000, train loss: 5.330253\n",
      "==>>> epoch: 5, batch index: 27000, train loss: 10.899481\n",
      "==>>> epoch: 5, batch index: 28000, train loss: 1.153621\n",
      "==>>> epoch: 5, batch index: 29000, train loss: 10.717351\n",
      "==>>> epoch: 5, batch index: 30000, train loss: 1.940824\n",
      "==>>> epoch: 5, batch index: 31000, train loss: 9.990210\n",
      "==>>> epoch: 5, batch index: 32000, train loss: 2.944649\n",
      "==>>> epoch: 5, batch index: 33000, train loss: 13.154343\n",
      "==>>> epoch: 5, batch index: 34000, train loss: 5.991374\n",
      "==>>> epoch: 5, batch index: 35000, train loss: 12.766047\n",
      "==>>> epoch: 5, batch index: 36000, train loss: 13.506754\n",
      "==>>> epoch: 5, batch index: 37000, train loss: 0.942567\n",
      "==>>> epoch: 5, batch index: 38000, train loss: 8.935575\n",
      "==>>> epoch: 5, batch index: 39000, train loss: 1.726831\n",
      "==>>> epoch: 5, batch index: 40000, train loss: 4.645707\n",
      "==>>> epoch: 5, batch index: 41000, train loss: 7.546711\n",
      "==>>> epoch: 5, batch index: 42000, train loss: 13.360731\n",
      "==>>> epoch: 5, batch index: 43000, train loss: 1.863850\n",
      "==>>> epoch: 5, batch index: 44000, train loss: 10.778145\n",
      "==>>> epoch: 5, batch index: 45000, train loss: 17.798281\n",
      "==>>> epoch: 5, batch index: 45053, train loss: 0.164409\n",
      "==>>> epoch: 5, batch index: 1000, test loss: 1.346823, acc: 0.774\n",
      "tensor([6., 6.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 5, batch index: 2000, test loss: 1.317792, acc: 0.800\n",
      "tensor([5., 5.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 5, batch index: 3000, test loss: 0.914562, acc: 0.795\n",
      "tensor([5., 7.], device='cuda:0') tensor([[6.],\n",
      "        [6.]], device='cuda:0')\n",
      "==>>> epoch: 5, batch index: 4000, test loss: 1.926524, acc: 0.736\n",
      "tensor([4., 5.], device='cuda:0') tensor([[4.],\n",
      "        [4.]], device='cuda:0')\n",
      "==>>> epoch: 5, batch index: 5000, test loss: 3.650660, acc: 0.717\n",
      "tensor([7., 4.], device='cuda:0') tensor([[4.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 5, batch index: 6000, test loss: 3.506830, acc: 0.634\n",
      "tensor([5., 5.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 5, batch index: 7000, test loss: 4.323529, acc: 0.543\n",
      "tensor([5., 5.], device='cuda:0') tensor([[3.],\n",
      "        [3.]], device='cuda:0')\n",
      "==>>> epoch: 5, batch index: 8000, test loss: 6.566821, acc: 0.475\n",
      "tensor([5., 5.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 5, batch index: 9000, test loss: 9.751775, acc: 0.423\n",
      "tensor([5., 5.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 5, batch index: 10000, test loss: 14.959014, acc: 0.380\n",
      "tensor([5., 5.], device='cuda:0') tensor([[9.],\n",
      "        [9.]], device='cuda:0')\n",
      "==>>> epoch: 5, batch index: 11000, test loss: 16.170961, acc: 0.346\n",
      "tensor([5., 5.], device='cuda:0') tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 5, batch index: 12000, test loss: 8.830358, acc: 0.317\n",
      "tensor([5., 5.], device='cuda:0') tensor([[8.],\n",
      "        [8.]], device='cuda:0')\n",
      "==>>> epoch: 5, batch index: 13000, test loss: 9.772741, acc: 0.293\n",
      "tensor([5., 5.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 5, batch index: 13526, test loss: 5.618127, acc: 0.281\n",
      "tensor([5., 3.], device='cuda:0') tensor([[3.],\n",
      "        [0.]], device='cuda:0')\n",
      "==>>> epoch: 6, batch index: 1000, train loss: 2.125280\n",
      "==>>> epoch: 6, batch index: 2000, train loss: 1.481746\n",
      "==>>> epoch: 6, batch index: 3000, train loss: 7.015396\n",
      "==>>> epoch: 6, batch index: 4000, train loss: 9.955603\n",
      "==>>> epoch: 6, batch index: 5000, train loss: 7.860170\n",
      "==>>> epoch: 6, batch index: 6000, train loss: 0.339160\n",
      "==>>> epoch: 6, batch index: 7000, train loss: 0.375487\n",
      "==>>> epoch: 6, batch index: 8000, train loss: 8.107621\n",
      "==>>> epoch: 6, batch index: 9000, train loss: 8.792336\n",
      "==>>> epoch: 6, batch index: 10000, train loss: 8.012659\n",
      "==>>> epoch: 6, batch index: 11000, train loss: 19.120588\n",
      "==>>> epoch: 6, batch index: 12000, train loss: 9.898021\n",
      "==>>> epoch: 6, batch index: 13000, train loss: 9.783663\n",
      "==>>> epoch: 6, batch index: 14000, train loss: 9.042686\n",
      "==>>> epoch: 6, batch index: 15000, train loss: 5.451125\n",
      "==>>> epoch: 6, batch index: 16000, train loss: 5.139682\n",
      "==>>> epoch: 6, batch index: 17000, train loss: 4.883179\n",
      "==>>> epoch: 6, batch index: 18000, train loss: 8.770411\n",
      "==>>> epoch: 6, batch index: 19000, train loss: 3.764348\n",
      "==>>> epoch: 6, batch index: 20000, train loss: 2.400678\n",
      "==>>> epoch: 6, batch index: 21000, train loss: 17.148647\n",
      "==>>> epoch: 6, batch index: 22000, train loss: 2.169830\n",
      "==>>> epoch: 6, batch index: 23000, train loss: 12.752655\n",
      "==>>> epoch: 6, batch index: 24000, train loss: 5.906521\n",
      "==>>> epoch: 6, batch index: 25000, train loss: 1.557674\n",
      "==>>> epoch: 6, batch index: 26000, train loss: 11.689458\n",
      "==>>> epoch: 6, batch index: 27000, train loss: 4.181581\n",
      "==>>> epoch: 6, batch index: 28000, train loss: 4.524709\n",
      "==>>> epoch: 6, batch index: 29000, train loss: 4.182911\n",
      "==>>> epoch: 6, batch index: 30000, train loss: 15.123829\n",
      "==>>> epoch: 6, batch index: 31000, train loss: 7.715476\n",
      "==>>> epoch: 6, batch index: 32000, train loss: 4.547928\n",
      "==>>> epoch: 6, batch index: 33000, train loss: 8.005214\n",
      "==>>> epoch: 6, batch index: 34000, train loss: 8.936796\n",
      "==>>> epoch: 6, batch index: 35000, train loss: 15.445076\n",
      "==>>> epoch: 6, batch index: 36000, train loss: 5.406655\n",
      "==>>> epoch: 6, batch index: 37000, train loss: 4.821888\n",
      "==>>> epoch: 6, batch index: 38000, train loss: 12.362059\n",
      "==>>> epoch: 6, batch index: 39000, train loss: 3.077482\n",
      "==>>> epoch: 6, batch index: 40000, train loss: 0.943993\n",
      "==>>> epoch: 6, batch index: 41000, train loss: 8.700830\n",
      "==>>> epoch: 6, batch index: 42000, train loss: 5.615870\n",
      "==>>> epoch: 6, batch index: 43000, train loss: 6.520405\n",
      "==>>> epoch: 6, batch index: 44000, train loss: 1.895961\n",
      "==>>> epoch: 6, batch index: 45000, train loss: 10.532607\n",
      "==>>> epoch: 6, batch index: 45053, train loss: 13.917246\n",
      "==>>> epoch: 6, batch index: 1000, test loss: 0.861917, acc: 0.657\n",
      "tensor([4., 5.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 6, batch index: 2000, test loss: 0.481420, acc: 0.685\n",
      "tensor([4., 5.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 6, batch index: 3000, test loss: 0.763861, acc: 0.649\n",
      "tensor([4., 5.], device='cuda:0') tensor([[6.],\n",
      "        [6.]], device='cuda:0')\n",
      "==>>> epoch: 6, batch index: 4000, test loss: 1.406116, acc: 0.638\n",
      "tensor([4., 5.], device='cuda:0') tensor([[4.],\n",
      "        [4.]], device='cuda:0')\n",
      "==>>> epoch: 6, batch index: 5000, test loss: 2.559294, acc: 0.704\n",
      "tensor([6., 4.], device='cuda:0') tensor([[4.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 6, batch index: 6000, test loss: 4.262395, acc: 0.636\n",
      "tensor([4., 4.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 6, batch index: 7000, test loss: 4.153868, acc: 0.545\n",
      "tensor([4., 4.], device='cuda:0') tensor([[3.],\n",
      "        [3.]], device='cuda:0')\n",
      "==>>> epoch: 6, batch index: 8000, test loss: 7.489572, acc: 0.477\n",
      "tensor([4., 4.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 6, batch index: 9000, test loss: 8.634562, acc: 0.424\n",
      "tensor([4., 4.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 6, batch index: 10000, test loss: 16.474635, acc: 0.382\n",
      "tensor([4., 4.], device='cuda:0') tensor([[9.],\n",
      "        [9.]], device='cuda:0')\n",
      "==>>> epoch: 6, batch index: 11000, test loss: 14.849067, acc: 0.347\n",
      "tensor([4., 4.], device='cuda:0') tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 6, batch index: 12000, test loss: 9.787742, acc: 0.318\n",
      "tensor([4., 4.], device='cuda:0') tensor([[8.],\n",
      "        [8.]], device='cuda:0')\n",
      "==>>> epoch: 6, batch index: 13000, test loss: 8.609623, acc: 0.294\n",
      "tensor([4., 4.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 6, batch index: 13526, test loss: 4.781839, acc: 0.282\n",
      "tensor([4., 3.], device='cuda:0') tensor([[3.],\n",
      "        [0.]], device='cuda:0')\n",
      "==>>> epoch: 7, batch index: 1000, train loss: 5.495243\n",
      "==>>> epoch: 7, batch index: 2000, train loss: 4.751357\n",
      "==>>> epoch: 7, batch index: 3000, train loss: 15.370011\n",
      "==>>> epoch: 7, batch index: 4000, train loss: 7.152705\n",
      "==>>> epoch: 7, batch index: 5000, train loss: 1.056182\n",
      "==>>> epoch: 7, batch index: 6000, train loss: 8.726620\n",
      "==>>> epoch: 7, batch index: 7000, train loss: 2.504736\n",
      "==>>> epoch: 7, batch index: 8000, train loss: 11.133204\n",
      "==>>> epoch: 7, batch index: 9000, train loss: 9.876019\n",
      "==>>> epoch: 7, batch index: 10000, train loss: 2.884082\n",
      "==>>> epoch: 7, batch index: 11000, train loss: 7.763118\n",
      "==>>> epoch: 7, batch index: 12000, train loss: 2.174734\n",
      "==>>> epoch: 7, batch index: 13000, train loss: 9.166308\n",
      "==>>> epoch: 7, batch index: 14000, train loss: 2.810531\n",
      "==>>> epoch: 7, batch index: 15000, train loss: 0.934952\n",
      "==>>> epoch: 7, batch index: 16000, train loss: 3.433322\n",
      "==>>> epoch: 7, batch index: 17000, train loss: 3.305411\n",
      "==>>> epoch: 7, batch index: 18000, train loss: 9.053599\n",
      "==>>> epoch: 7, batch index: 19000, train loss: 7.489741\n",
      "==>>> epoch: 7, batch index: 20000, train loss: 10.645703\n",
      "==>>> epoch: 7, batch index: 21000, train loss: 1.407439\n",
      "==>>> epoch: 7, batch index: 22000, train loss: 2.843526\n",
      "==>>> epoch: 7, batch index: 23000, train loss: 2.329422\n",
      "==>>> epoch: 7, batch index: 24000, train loss: 2.114165\n",
      "==>>> epoch: 7, batch index: 25000, train loss: 5.011455\n",
      "==>>> epoch: 7, batch index: 26000, train loss: 3.951123\n",
      "==>>> epoch: 7, batch index: 27000, train loss: 7.706552\n",
      "==>>> epoch: 7, batch index: 28000, train loss: 7.955458\n",
      "==>>> epoch: 7, batch index: 29000, train loss: 2.306687\n",
      "==>>> epoch: 7, batch index: 30000, train loss: 10.707686\n",
      "==>>> epoch: 7, batch index: 31000, train loss: 5.195018\n",
      "==>>> epoch: 7, batch index: 32000, train loss: 9.893847\n",
      "==>>> epoch: 7, batch index: 33000, train loss: 6.702531\n",
      "==>>> epoch: 7, batch index: 34000, train loss: 5.245432\n",
      "==>>> epoch: 7, batch index: 35000, train loss: 1.765309\n",
      "==>>> epoch: 7, batch index: 36000, train loss: 1.219950\n",
      "==>>> epoch: 7, batch index: 37000, train loss: 9.207665\n",
      "==>>> epoch: 7, batch index: 38000, train loss: 4.024620\n",
      "==>>> epoch: 7, batch index: 39000, train loss: 1.105084\n",
      "==>>> epoch: 7, batch index: 40000, train loss: 4.333011\n",
      "==>>> epoch: 7, batch index: 41000, train loss: 4.851656\n",
      "==>>> epoch: 7, batch index: 42000, train loss: 2.221775\n",
      "==>>> epoch: 7, batch index: 43000, train loss: 12.817073\n",
      "==>>> epoch: 7, batch index: 44000, train loss: 7.328477\n",
      "==>>> epoch: 7, batch index: 45000, train loss: 1.192000\n",
      "==>>> epoch: 7, batch index: 45053, train loss: 2.623595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 7, batch index: 1000, test loss: 0.824036, acc: 0.841\n",
      "tensor([6., 5.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 7, batch index: 2000, test loss: 1.018748, acc: 0.874\n",
      "tensor([4., 5.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 7, batch index: 3000, test loss: 0.812503, acc: 0.844\n",
      "tensor([5., 6.], device='cuda:0') tensor([[6.],\n",
      "        [6.]], device='cuda:0')\n",
      "==>>> epoch: 7, batch index: 4000, test loss: 1.733782, acc: 0.767\n",
      "tensor([4., 5.], device='cuda:0') tensor([[4.],\n",
      "        [4.]], device='cuda:0')\n",
      "==>>> epoch: 7, batch index: 5000, test loss: 2.901702, acc: 0.749\n",
      "tensor([6., 4.], device='cuda:0') tensor([[4.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 7, batch index: 6000, test loss: 3.082812, acc: 0.662\n",
      "tensor([5., 5.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 7, batch index: 7000, test loss: 4.462949, acc: 0.568\n",
      "tensor([5., 5.], device='cuda:0') tensor([[3.],\n",
      "        [3.]], device='cuda:0')\n",
      "==>>> epoch: 7, batch index: 8000, test loss: 6.040992, acc: 0.497\n",
      "tensor([5., 5.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 7, batch index: 9000, test loss: 10.468229, acc: 0.442\n",
      "tensor([5., 5.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 7, batch index: 10000, test loss: 14.072144, acc: 0.398\n",
      "tensor([5., 5.], device='cuda:0') tensor([[9.],\n",
      "        [9.]], device='cuda:0')\n",
      "==>>> epoch: 7, batch index: 11000, test loss: 17.012057, acc: 0.361\n",
      "tensor([5., 5.], device='cuda:0') tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 7, batch index: 12000, test loss: 8.283440, acc: 0.331\n",
      "tensor([5., 5.], device='cuda:0') tensor([[8.],\n",
      "        [8.]], device='cuda:0')\n",
      "==>>> epoch: 7, batch index: 13000, test loss: 10.517148, acc: 0.306\n",
      "tensor([5., 5.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 7, batch index: 13526, test loss: 6.163504, acc: 0.294\n",
      "tensor([5., 3.], device='cuda:0') tensor([[3.],\n",
      "        [0.]], device='cuda:0')\n",
      "==>>> epoch: 8, batch index: 1000, train loss: 4.222819\n",
      "==>>> epoch: 8, batch index: 2000, train loss: 7.751230\n",
      "==>>> epoch: 8, batch index: 3000, train loss: 1.532113\n",
      "==>>> epoch: 8, batch index: 4000, train loss: 0.674334\n",
      "==>>> epoch: 8, batch index: 5000, train loss: 12.478580\n",
      "==>>> epoch: 8, batch index: 6000, train loss: 7.910224\n",
      "==>>> epoch: 8, batch index: 7000, train loss: 5.803923\n",
      "==>>> epoch: 8, batch index: 8000, train loss: 14.850791\n",
      "==>>> epoch: 8, batch index: 9000, train loss: 13.834457\n",
      "==>>> epoch: 8, batch index: 10000, train loss: 6.691693\n",
      "==>>> epoch: 8, batch index: 11000, train loss: 2.510168\n",
      "==>>> epoch: 8, batch index: 12000, train loss: 9.016573\n",
      "==>>> epoch: 8, batch index: 13000, train loss: 4.244869\n",
      "==>>> epoch: 8, batch index: 14000, train loss: 9.093267\n",
      "==>>> epoch: 8, batch index: 15000, train loss: 6.421480\n",
      "==>>> epoch: 8, batch index: 16000, train loss: 14.106672\n",
      "==>>> epoch: 8, batch index: 17000, train loss: 9.457185\n",
      "==>>> epoch: 8, batch index: 18000, train loss: 4.065332\n",
      "==>>> epoch: 8, batch index: 19000, train loss: 10.679066\n",
      "==>>> epoch: 8, batch index: 20000, train loss: 6.663239\n",
      "==>>> epoch: 8, batch index: 21000, train loss: 0.190303\n",
      "==>>> epoch: 8, batch index: 22000, train loss: 2.110049\n",
      "==>>> epoch: 8, batch index: 23000, train loss: 6.711907\n",
      "==>>> epoch: 8, batch index: 24000, train loss: 5.346527\n",
      "==>>> epoch: 8, batch index: 25000, train loss: 5.832697\n",
      "==>>> epoch: 8, batch index: 26000, train loss: 14.853312\n",
      "==>>> epoch: 8, batch index: 27000, train loss: 8.715669\n",
      "==>>> epoch: 8, batch index: 28000, train loss: 6.275416\n",
      "==>>> epoch: 8, batch index: 29000, train loss: 2.410293\n",
      "==>>> epoch: 8, batch index: 30000, train loss: 0.524539\n",
      "==>>> epoch: 8, batch index: 31000, train loss: 0.531802\n",
      "==>>> epoch: 8, batch index: 32000, train loss: 2.967351\n",
      "==>>> epoch: 8, batch index: 33000, train loss: 14.204220\n",
      "==>>> epoch: 8, batch index: 34000, train loss: 12.794619\n",
      "==>>> epoch: 8, batch index: 35000, train loss: 3.535336\n",
      "==>>> epoch: 8, batch index: 36000, train loss: 6.347522\n",
      "==>>> epoch: 8, batch index: 37000, train loss: 1.036564\n",
      "==>>> epoch: 8, batch index: 38000, train loss: 9.348452\n",
      "==>>> epoch: 8, batch index: 39000, train loss: 3.966071\n",
      "==>>> epoch: 8, batch index: 40000, train loss: 7.819412\n",
      "==>>> epoch: 8, batch index: 41000, train loss: 10.731012\n",
      "==>>> epoch: 8, batch index: 42000, train loss: 0.016294\n",
      "==>>> epoch: 8, batch index: 43000, train loss: 3.310431\n",
      "==>>> epoch: 8, batch index: 44000, train loss: 6.726334\n",
      "==>>> epoch: 8, batch index: 45000, train loss: 0.016549\n",
      "==>>> epoch: 8, batch index: 45053, train loss: 0.003551\n",
      "==>>> epoch: 8, batch index: 1000, test loss: 0.650443, acc: 0.832\n",
      "tensor([5., 5.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 8, batch index: 2000, test loss: 0.526124, acc: 0.865\n",
      "tensor([4., 4.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 8, batch index: 3000, test loss: 0.546820, acc: 0.804\n",
      "tensor([5., 6.], device='cuda:0') tensor([[6.],\n",
      "        [6.]], device='cuda:0')\n",
      "==>>> epoch: 8, batch index: 4000, test loss: 1.325225, acc: 0.729\n",
      "tensor([4., 5.], device='cuda:0') tensor([[4.],\n",
      "        [4.]], device='cuda:0')\n",
      "==>>> epoch: 8, batch index: 5000, test loss: 2.560406, acc: 0.737\n",
      "tensor([6., 4.], device='cuda:0') tensor([[4.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 8, batch index: 6000, test loss: 3.836153, acc: 0.658\n",
      "tensor([5., 5.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 8, batch index: 7000, test loss: 4.238423, acc: 0.564\n",
      "tensor([5., 5.], device='cuda:0') tensor([[3.],\n",
      "        [3.]], device='cuda:0')\n",
      "==>>> epoch: 8, batch index: 8000, test loss: 6.971031, acc: 0.493\n",
      "tensor([5., 5.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 8, batch index: 9000, test loss: 9.242239, acc: 0.439\n",
      "tensor([5., 5.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 8, batch index: 10000, test loss: 15.628785, acc: 0.395\n",
      "tensor([5., 5.], device='cuda:0') tensor([[9.],\n",
      "        [9.]], device='cuda:0')\n",
      "==>>> epoch: 8, batch index: 11000, test loss: 15.569744, acc: 0.359\n",
      "tensor([5., 5.], device='cuda:0') tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 8, batch index: 12000, test loss: 9.250081, acc: 0.329\n",
      "tensor([5., 5.], device='cuda:0') tensor([[8.],\n",
      "        [8.]], device='cuda:0')\n",
      "==>>> epoch: 8, batch index: 13000, test loss: 9.242643, acc: 0.304\n",
      "tensor([5., 5.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 8, batch index: 13526, test loss: 5.234423, acc: 0.292\n",
      "tensor([5., 3.], device='cuda:0') tensor([[3.],\n",
      "        [0.]], device='cuda:0')\n",
      "==>>> epoch: 9, batch index: 1000, train loss: 5.462920\n",
      "==>>> epoch: 9, batch index: 2000, train loss: 13.882931\n",
      "==>>> epoch: 9, batch index: 3000, train loss: 6.902099\n",
      "==>>> epoch: 9, batch index: 4000, train loss: 0.445957\n",
      "==>>> epoch: 9, batch index: 5000, train loss: 1.613086\n",
      "==>>> epoch: 9, batch index: 6000, train loss: 13.565649\n",
      "==>>> epoch: 9, batch index: 7000, train loss: 5.064925\n",
      "==>>> epoch: 9, batch index: 8000, train loss: 0.420625\n",
      "==>>> epoch: 9, batch index: 9000, train loss: 11.696301\n",
      "==>>> epoch: 9, batch index: 10000, train loss: 5.737728\n",
      "==>>> epoch: 9, batch index: 11000, train loss: 0.434321\n",
      "==>>> epoch: 9, batch index: 12000, train loss: 7.729709\n",
      "==>>> epoch: 9, batch index: 13000, train loss: 9.126163\n",
      "==>>> epoch: 9, batch index: 14000, train loss: 7.771826\n",
      "==>>> epoch: 9, batch index: 15000, train loss: 1.586990\n",
      "==>>> epoch: 9, batch index: 16000, train loss: 0.757919\n",
      "==>>> epoch: 9, batch index: 17000, train loss: 7.424046\n",
      "==>>> epoch: 9, batch index: 18000, train loss: 0.338213\n",
      "==>>> epoch: 9, batch index: 19000, train loss: 7.946339\n",
      "==>>> epoch: 9, batch index: 20000, train loss: 4.155921\n",
      "==>>> epoch: 9, batch index: 21000, train loss: 8.572958\n",
      "==>>> epoch: 9, batch index: 22000, train loss: 8.543576\n",
      "==>>> epoch: 9, batch index: 23000, train loss: 0.418689\n",
      "==>>> epoch: 9, batch index: 24000, train loss: 9.748750\n",
      "==>>> epoch: 9, batch index: 25000, train loss: 11.810341\n",
      "==>>> epoch: 9, batch index: 26000, train loss: 4.873986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 9, batch index: 27000, train loss: 4.446368\n",
      "==>>> epoch: 9, batch index: 28000, train loss: 7.265223\n",
      "==>>> epoch: 9, batch index: 29000, train loss: 4.656508\n",
      "==>>> epoch: 9, batch index: 30000, train loss: 5.543957\n",
      "==>>> epoch: 9, batch index: 31000, train loss: 10.844027\n",
      "==>>> epoch: 9, batch index: 32000, train loss: 0.273107\n",
      "==>>> epoch: 9, batch index: 33000, train loss: 6.013879\n",
      "==>>> epoch: 9, batch index: 34000, train loss: 4.697891\n",
      "==>>> epoch: 9, batch index: 35000, train loss: 8.194887\n",
      "==>>> epoch: 9, batch index: 36000, train loss: 1.447650\n",
      "==>>> epoch: 9, batch index: 37000, train loss: 13.786537\n",
      "==>>> epoch: 9, batch index: 38000, train loss: 6.119644\n",
      "==>>> epoch: 9, batch index: 39000, train loss: 9.230254\n",
      "==>>> epoch: 9, batch index: 40000, train loss: 10.083046\n",
      "==>>> epoch: 9, batch index: 41000, train loss: 3.678915\n",
      "==>>> epoch: 9, batch index: 42000, train loss: 1.713620\n",
      "==>>> epoch: 9, batch index: 43000, train loss: 2.536857\n",
      "==>>> epoch: 9, batch index: 44000, train loss: 6.842369\n",
      "==>>> epoch: 9, batch index: 45000, train loss: 4.923330\n",
      "==>>> epoch: 9, batch index: 45053, train loss: 25.151646\n",
      "==>>> epoch: 9, batch index: 1000, test loss: 0.699317, acc: 0.895\n",
      "tensor([6., 5.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 9, batch index: 2000, test loss: 0.721891, acc: 0.922\n",
      "tensor([4., 5.], device='cuda:0') tensor([[6.],\n",
      "        [5.]], device='cuda:0')\n",
      "==>>> epoch: 9, batch index: 3000, test loss: 0.575042, acc: 0.880\n",
      "tensor([5., 6.], device='cuda:0') tensor([[6.],\n",
      "        [6.]], device='cuda:0')\n",
      "==>>> epoch: 9, batch index: 4000, test loss: 1.500479, acc: 0.779\n",
      "tensor([4., 5.], device='cuda:0') tensor([[4.],\n",
      "        [4.]], device='cuda:0')\n",
      "==>>> epoch: 9, batch index: 5000, test loss: 2.820142, acc: 0.754\n",
      "tensor([5., 4.], device='cuda:0') tensor([[4.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 9, batch index: 6000, test loss: 3.255414, acc: 0.664\n",
      "tensor([5., 5.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 9, batch index: 7000, test loss: 4.401789, acc: 0.569\n",
      "tensor([5., 5.], device='cuda:0') tensor([[3.],\n",
      "        [3.]], device='cuda:0')\n",
      "==>>> epoch: 9, batch index: 8000, test loss: 6.255833, acc: 0.498\n",
      "tensor([5., 5.], device='cuda:0') tensor([[7.],\n",
      "        [7.]], device='cuda:0')\n",
      "==>>> epoch: 9, batch index: 9000, test loss: 10.167666, acc: 0.443\n",
      "tensor([5., 5.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 9, batch index: 10000, test loss: 14.436777, acc: 0.398\n",
      "tensor([5., 5.], device='cuda:0') tensor([[9.],\n",
      "        [9.]], device='cuda:0')\n",
      "==>>> epoch: 9, batch index: 11000, test loss: 16.659782, acc: 0.362\n",
      "tensor([5., 5.], device='cuda:0') tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "==>>> epoch: 9, batch index: 12000, test loss: 8.507031, acc: 0.332\n",
      "tensor([5., 5.], device='cuda:0') tensor([[8.],\n",
      "        [8.]], device='cuda:0')\n",
      "==>>> epoch: 9, batch index: 13000, test loss: 10.204988, acc: 0.306\n",
      "tensor([5., 5.], device='cuda:0') tensor([[2.],\n",
      "        [2.]], device='cuda:0')\n",
      "==>>> epoch: 9, batch index: 13526, test loss: 5.933918, acc: 0.295\n",
      "tensor([5., 3.], device='cuda:0') tensor([[3.],\n",
      "        [0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "global epoch #declear epoch global, to be used later by torch.save() \n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    ave_loss = 0\n",
    "    global loss #declear loss global, to be used later by torch.save() \n",
    "    for batch_idx, diction in enumerate(train_loader):\n",
    "        model.train() #set model to traning mode\n",
    "        optimizer.zero_grad()\n",
    "        x, target = diction['image'], diction['rating'] #extract training data for this batch\n",
    "        # target = target.resize_(20)\n",
    "        x, target = x.float(), target.float() #set datatype\n",
    "        x, target = x.to(device), target.to(device) #transfer to GPU\n",
    "        x, target = Variable(x), Variable(target) #set to pytorch datatype: variable\n",
    "        out = model(x) #forward pass\n",
    "        loss = criterion(out, target.resize_([2, 1])) #calculate loss\n",
    "        ave_loss = ave_loss * 0.9 + loss.item() * 0.1 \n",
    "        loss.backward() #back propagation with calculated loss\n",
    "        optimizer.step() #calculate gradient and step\n",
    "        if (batch_idx + 1) % 1000 == 0 or (batch_idx + 1) == len(train_loader):\n",
    "            print('==>>> epoch: {}, batch index: {}, train loss: {:.6f}'.format(epoch, batch_idx + 1, loss))\n",
    "\n",
    "    correct_cnt, ave_loss = 0, 0\n",
    "    total_cnt = 0\n",
    "    for batch_idx, diction in enumerate(val_loader):\n",
    "        model.eval() #set model to evaluation mode\n",
    "        x, target = diction['image'], diction['rating']\n",
    "        # target = target.resize_(20)\n",
    "        x, target = x.float(), target.float()\n",
    "        x, target = x.to(device), target.to(device)\n",
    "        x, target = Variable(x), Variable(target)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target.resize_([2, 1]))\n",
    "        pred_label = out.data.int().float().resize_(2) \n",
    "        # make out.data int to remove decimals, revert to float and resize for the datatype to match when using .sum()\n",
    "        total_cnt += x.data.size()[0]\n",
    "        correct_cnt += (pred_label == target.data).sum()\n",
    "        ave_loss = ave_loss * 0.9 + loss.item() * 0.1 #smooth average\n",
    "        if (batch_idx + 1) % 1000 == 0 or (batch_idx + 1) == len(val_loader):\n",
    "            print(\n",
    "            '==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
    "                epoch, batch_idx + 1, ave_loss, correct_cnt.item() * 1.0 / total_cnt))\n",
    "            print(pred_label.data, target.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"LN_VGG16\"\n",
    "checkpoint_save_dir = r\"C:\\Users\\Leo's PC\\PycharmProjects\\PD\\Model Checkpoints\"\n",
    "checkpoint_file = open(checkpoint_save_dir + \"\\\\\" + model_name + \"_\" + \"E\" + str(epoch) + \"_\" + time.strftime(\"%m.%d.%Y_%H.%M.%S\") \n",
    "                       + \".tar\", 'wb')\n",
    "\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, checkpoint_file)\n",
    "\n",
    "checkpoint_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(open(checkpoint_save_dir + \"\\LN_VGG16_E0_06.27.2020_16.25.57.tar\", 'rb'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample = AVA[25000]\n",
    "print(i, sample['image'].size(), sample['rating'])\n",
    "img = sample['image'][1]\n",
    "img = np.array(img)\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
