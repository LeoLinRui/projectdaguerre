{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cython\n",
    "from numba import njit\n",
    "from joblib import Parallel, delayed\n",
    "import shutil\n",
    "\n",
    "import cv2 as cv\n",
    "from skimage import transform\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "\n",
    "image_dir = r\"C:\\Users\\Leo's PC\\Desktop\\images\"\n",
    "csv_dir = r\"C:\\Users\\Leo's PC\\Desktop\\AVA.txt\"\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgeDetection(data):\n",
    "    out = cv.Canny(data, threshold1=100, threshold2=150)\n",
    "    out = np.reshape(out, (data.shape[0], data.shape[1]))\n",
    "    return out\n",
    "\n",
    "def convert2HSL(data):\n",
    "    try:\n",
    "        return cv.cvtColor(data, cv.COLOR_BGR2HLS)\n",
    "    except:\n",
    "        return cv.cvtColor(cv.cvtColor(data, cv.COLOR_GRAY2BGR), cv.COLOR_BGR2HLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def hslForLoop(data, out_array):\n",
    "    for idx, value in np.ndenumerate(data): \n",
    "        if idx[2] == 0: # Only enter Hue mapping when on the first value of each pixel\n",
    "            # deviation = ((value % 21.25) / 21.25 * 2) - 1 \n",
    "            # deviation is between -1 and 1. Representing the distance from the CENTER of that section\n",
    "            if value != 0: #when it's not a b&w image w/out hue value\n",
    "                out_array[int(np.floor(value / 14.92))][idx[0]][idx[1]] = 255\n",
    "            # 180/12 = 14.91. np.floor(pixel[0] / 21.251) is the corresponding map index\n",
    "            # 14.92 is used instead of 14.91 to avoid getting idx[12] (the luminance map) when value==179\n",
    "            # [idx[0]][idx[1] points to the correct pixel location\n",
    "\n",
    "        elif idx[2] == 1: # Only enter Luminance mapping when on the second value of each pixel\n",
    "            out_array[12][idx[0]][idx[1]] = value\n",
    "            # sat value to from 0 to 255 and put it at the corresponding location\n",
    "\n",
    "        elif idx[2] == 2: # Only enter Saturation mapping when on the third value of each pixel\n",
    "            out_array[13][idx[0]][idx[1]] = value\n",
    "            # sat value to from 0 to 255 and put it at the corresponding location\n",
    "    return out_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hslMap(data):\n",
    "    out_array = np.zeros(data.shape[0] * data.shape[1] * 14, dtype='uint8').reshape(14, data.shape[0], data.shape[1])\n",
    "    # create an array with (img_width * img_height * (12+1+1)) zeros and shape it into 14 maps w/ 0s.\n",
    "    \n",
    "    out_array = hslForLoop(data=data, out_array=out_array)\n",
    "    \n",
    "    for i in range(12):\n",
    "        # cv.fastNlMeansDenoising(out_array[i], out_array[i], 30.0, 7, 21)\n",
    "        out_array[i] = cv.blur(out_array[i],(3,3))\n",
    "    out_array[12] = cv.blur(out_array[12],(15,15))\n",
    "    out_array[13] = cv.blur(out_array[13],(5,5))\n",
    "    \n",
    "    return out_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvFeatureMaps(data):\n",
    "    # some datatype processing here\n",
    "    out = np.append(hslMap(convert2HSL(data)), [edgeDetection(data)], axis=0)\n",
    "    # some datatype processing here\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread('Sample Images/example7.jpg')\n",
    "image = cvFeatureMaps(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(image)):\n",
    "    cv.namedWindow( \"Display window\", cv.WINDOW_AUTOSIZE)\n",
    "    cv.imshow(\"Display window\", image[i])\n",
    "    cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge detection tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncv.namedWindow( \"Display window\", cv.WINDOW_AUTOSIZE)\\ncv.imshow(\"Display window\", edge)\\ncv.waitKey(0)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv.imread(r\"C:\\Users\\Leo's PC\\Desktop\\RISD Summer HW\\WeChat Image_20200712120050.jpg\")\n",
    "edge = edgeDetection(image)\n",
    "\n",
    "cv.imwrite(r\"C:\\Users\\Leo's PC\\Desktop\\RISD Summer HW\\WeChat Image_20200712120050_edge.jpg\", edge)\n",
    "\n",
    "'''\n",
    "cv.namedWindow( \"Display window\", cv.WINDOW_AUTOSIZE)\n",
    "cv.imshow(\"Display window\", edge)\n",
    "cv.waitKey(0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to process the entire AVA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SalGanCV(csv_file, save_dir):\n",
    "    \n",
    "    csv = pd.read_csv(csv_file, sep=' ')\n",
    "    img_name_array = [subfolders for subfolders in os.listdir(save_dir)]\n",
    "    \n",
    "    for csv_idx, row in csv.iterrows(): #traverse the enitre csv file\n",
    "        img_name = row[1]\n",
    "        if (str(img_name)) in img_name_array:\n",
    "            img = Image.open(os.path.join(save_dir, str(img_name), '0.jpg'))\n",
    "            size = np.flip(np.array(img.size))\n",
    "            img = np.array(img)\n",
    "            \n",
    "            try:\n",
    "                maps = cvFeatureMaps(img)\n",
    "            except TypeError:\n",
    "                print(\"Image reading: TypeError. Skipped\")\n",
    "            else:\n",
    "                maps = np.reshape(maps, [15, size[0], size[1]])\n",
    "                maps = np.array(maps, dtype='uint8')\n",
    "                \n",
    "                folder_path = os.path.join(save_dir,str(img_name))\n",
    "                if os.path.exists(folder_path):\n",
    "                    for i in range(15):\n",
    "                        cv.imwrite(os.path.join(folder_path, str(i + 2) + '.jpg'), maps[i])\n",
    "                else: print('Folder not found. Skipped.')\n",
    "        if (csv_idx) % 10000 == 0: print('==>>> On CSV Index: {}'.format(csv_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> On CSV Index: 0\n",
      "==>>> On CSV Index: 10000\n",
      "==>>> On CSV Index: 20000\n",
      "==>>> On CSV Index: 30000\n",
      "==>>> On CSV Index: 40000\n",
      "==>>> On CSV Index: 50000\n",
      "==>>> On CSV Index: 60000\n",
      "==>>> On CSV Index: 70000\n",
      "==>>> On CSV Index: 80000\n",
      "==>>> On CSV Index: 90000\n",
      "==>>> On CSV Index: 100000\n",
      "==>>> On CSV Index: 110000\n",
      "==>>> On CSV Index: 120000\n",
      "==>>> On CSV Index: 130000\n",
      "==>>> On CSV Index: 140000\n",
      "==>>> On CSV Index: 150000\n",
      "==>>> On CSV Index: 160000\n",
      "==>>> On CSV Index: 170000\n",
      "==>>> On CSV Index: 180000\n",
      "==>>> On CSV Index: 190000\n",
      "==>>> On CSV Index: 200000\n",
      "==>>> On CSV Index: 210000\n",
      "==>>> On CSV Index: 220000\n",
      "==>>> On CSV Index: 230000\n",
      "==>>> On CSV Index: 240000\n",
      "==>>> On CSV Index: 250000\n"
     ]
    }
   ],
   "source": [
    "SalGanCV(csv_file=csv_dir, save_dir=r\"H:\\AVA Featuremap Dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
