{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import time\n",
    "import pickle\n",
    "import itertools \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import cv2\n",
    "from skimage import transform\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "\n",
    "from Datasets import *\n",
    "\n",
    "image_dir = r\"I:\\AVA_images\"\n",
    "pkl_dir= r\"H:\\AVAFeatures_pkl\"\n",
    "feature_dir = r'H:\\AVA Featuremaps'\n",
    "csv_dir = r\"C:\\Users\\Leo's PC\\Desktop\\AVA.txt\"\n",
    "checkpoint_save_dir = r\"I:\\Model Checkpoints\"\n",
    "cache_folder = r\"I:\\AVACache_Smooth\"\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255502 images found in the feature map directory.\n",
      "19999 images are found within the specified range\n",
      "Extremes: ('17640', 1.1810344827586208) ('491369', 7.399253731343284)\n",
      "1999 images with label 0. 2000 images with label 1.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train = AVAFeatureDataset_Binary_percent(csv_file=csv_dir, file_dir=feature_dir, pkl_dir=pkl_dir, start=0, end=209999, percent=0.5, transform=transforms.Compose([Rescale_list((224, 224)), ToNumpy_list()]))\n",
    "# Validation = AVAFeatureDataset_Binary_percent(csv_file=csv_dir, file_dir=feature_dir, pkl_dir=pkl_dir, start=210000, end=229999, percent=0.5, transform=transforms.Compose([Rescale_list((224, 224)), ToNumpy_list()]))\n",
    "Test = AVAFeatureDataset_Binary_percent(csv_file=csv_dir, file_dir=feature_dir, pkl_dir=pkl_dir, start=230000, end=249999, percent=0.1, transform=transforms.Compose([Rescale_list((224, 224)), ToNumpy_list()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Validation.CACHED_TRANSFORM, Validation.CACHED, Train.CACHED_TRANSFORM, Train.CACHED = True, True, True, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start building cache\n",
      "Cacheing complete. Took 318.4704387187958 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Train.build_cache(r'I:\\AVACache_Binary50%', TRANSFORM=True)\n",
    "# Validation.build_cache(r'I:\\AVACache_Binary50%', TRANSFORM=True)\n",
    "Test.build_cache(r'I:\\AVACache_Binary10%', TRANSFORM=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209999\n"
     ]
    }
   ],
   "source": [
    "print(Train.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('I:\\AVA_dataset_pkl/test_features_10%_Cached.pkl', 'wb') as fp:\n",
    "    pickle.dump(Test, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset and Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('I:\\AVA_dataset_pkl/train_features_10%_binary_Cached.pkl', 'rb') as fp:\n",
    "    Train = pickle.load(fp)\n",
    "    \n",
    "with open('I:\\AVA_dataset_pkl/validation_features_10%_binary_Cached.pkl', 'rb') as fp:\n",
    "    Validation = pickle.load(fp)\n",
    "\n",
    "with open('I:\\AVA_dataset_pkl/test_features_10%_Cached.pkl', 'rb') as fp:\n",
    "    Test = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset=Train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=Validation, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=Test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(next(enumerate(train_loader))[1]['image']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "\n",
    "class DeepFeaturesProcessor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepFeaturesProcessor, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=19, out_channels=32, kernel_size=[7,7], stride=2, padding=3)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=[5,5], stride=2, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=0)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=[3,3], stride=1, padding=1)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    @autocast()   \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class SceneProcessor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SceneProcessor, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Linear(2048, 1024)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    @autocast()    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class AugmentedDenseNet(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(AugmentedDenseNet, self).__init__()\n",
    "        \n",
    "        self.densenet = torchvision.models.densenet121(pretrained=True, progress=True).features\n",
    "        self.deep_feature_processor = DeepFeaturesProcessor()\n",
    "        self.scene_processor = SceneProcessor()\n",
    "        \n",
    "        self.pre_input = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=[7,7], stride=2, padding=3)\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=[7,7], stride=2, padding=3)\n",
    "        self.pool0 = nn.AdaptiveMaxPool2d(output_size=56)\n",
    "        self.dense_input = nn.Sequential(self.conv0, self.densenet.norm0, nn.ReLU(), self.pool0)\n",
    "        self.dense_block1 = self.densenet.denseblock1\n",
    "        self.dense_block2 = self.densenet.denseblock2\n",
    "        self.dense_block3 = self.densenet.denseblock3\n",
    "        self.dense_block4 = self.densenet.denseblock4\n",
    "        \n",
    "        self.dense_transition1 = self.densenet.transition1 \n",
    "        self.dense_transition2 = nn.Sequential(nn.Conv2d(in_channels=512, out_channels=192, kernel_size=[1,1], stride=1, padding=0),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.AvgPool2d(kernel_size = [2, 2], stride=2, padding=0))\n",
    "        self.dense_transition3 = self.densenet.transition3\n",
    "\n",
    "        self.pooling = nn.AvgPool2d(kernel_size = [7, 7], stride=7, padding=0)\n",
    "        \n",
    "        self.fc1 = nn.Linear(2048, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 2)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.bn1d1 = nn.BatchNorm1d(2048)\n",
    "        self.bn1d2 = nn.BatchNorm1d(1024)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.scene_processor.apply(init_weights)\n",
    "        self.deep_feature_processor.apply(init_weights)\n",
    "        self.pre_input.apply(init_weights)\n",
    "\n",
    "        \n",
    "    @autocast()\n",
    "    def forward(self, imagelist, scene, device):\n",
    "        \n",
    "        #self.densenet = self.densenet.to(device)\n",
    "        #self.deep_feature_processor = self.deep_feature_processor.to(device)\n",
    "        #self.scene_processor = self.scene_processor.to(device)\n",
    "        \n",
    "        # original_input = torch.from_numpy(imagelist[0])\n",
    "        original_input = imagelist[0].float()\n",
    "        #original_input = original_input.to(device)\n",
    "        dense_feature_out = self.pre_input(original_input)\n",
    "        dense_feature_out = self.dense_input(dense_feature_out)\n",
    "        dense_feature_out = self.dense_block1(dense_feature_out)\n",
    "        dense_feature_out = self.dense_transition1(dense_feature_out)\n",
    "        dense_feature_out = self.dense_block2(dense_feature_out)\n",
    "        dense_feature_out = self.dense_transition2(dense_feature_out)\n",
    "        \n",
    "        deep_feature_in = []\n",
    "        for feature in imagelist[1:20]:\n",
    "            feature = feature.float()\n",
    "            #feature = feature.to(device)\n",
    "            deep_feature_in.append(feature)\n",
    "        deep_feature_in = torch.cat(deep_feature_in, dim=1)\n",
    "        \n",
    "        deep_feature_out = self.deep_feature_processor(deep_feature_in)\n",
    "        dense_in = torch.cat([dense_feature_out, deep_feature_out], dim=1)\n",
    "        \n",
    "        dense_out = self.dense_block3(dense_in)\n",
    "        dense_out = self.dense_transition3(dense_out)\n",
    "        dense_out = self.dense_block4(dense_out)\n",
    "        dense_out = self.pooling(dense_out)\n",
    "        dense_out = dense_out.view(dense_out.size()[0], -1)\n",
    "        \n",
    "        # scene_input = torch.from_numpy(scene)\n",
    "        scene_input = scene.float()\n",
    "        #scene_input = scene_input.to(device)\n",
    "        scene_out = self.scene_processor(scene_input)\n",
    "        fc_in = torch.cat([dense_out, scene_out], dim=1)\n",
    "        \n",
    "        fc_out = self.fc1(fc_in)\n",
    "        fc_out = self.bn1d1(fc_out)\n",
    "        fc_out = self.dropout1(fc_out)\n",
    "        fc_out = self.relu(fc_out)\n",
    "        fc_out = self.fc2(fc_out)\n",
    "        fc_out = self.bn1d2(fc_out)\n",
    "        fc_out = self.dropout2(fc_out)\n",
    "        fc_out = self.relu(fc_out)\n",
    "        fc_out = self.fc3(fc_out)\n",
    "        fc_out = self.relu(fc_out)\n",
    "        fc_out = self.fc4(fc_out)\n",
    "        fc_out = self.softmax(fc_out)\n",
    "        \n",
    "        return fc_out\n",
    "\n",
    "    def name(self):\n",
    "        return \"FeatureNet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFeaturesProcessor_Light(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepFeaturesProcessor_Light, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=19, out_channels=32, kernel_size=[7,7], stride=2, padding=3)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=0)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=[5,5], stride=2, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=0)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=0)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=1)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=0)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    @autocast()   \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.pool4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.pool5(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class AugmentedLightNet(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(AugmentedLightNet, self).__init__()\n",
    "        \n",
    "        self.densenet = torchvision.models.densenet121(pretrained=True, progress=True).features\n",
    "        self.deep_feature_processor = DeepFeaturesProcessor_Light()\n",
    "        self.scene_processor = SceneProcessor()\n",
    "        \n",
    "        self.pre_input = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=[7,7], stride=2, padding=3)\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=[7,7], stride=2, padding=3)\n",
    "        self.pool0 = nn.AdaptiveMaxPool2d(output_size=56)\n",
    "        self.dense_input = nn.Sequential(self.conv0, self.densenet.norm0, nn.ReLU(), self.pool0)\n",
    "        self.dense_block1 = self.densenet.denseblock1\n",
    "        self.dense_block2 = self.densenet.denseblock2\n",
    "        self.dense_block3 = self.densenet.denseblock3\n",
    "        self.dense_block4 = self.densenet.denseblock4\n",
    "        \n",
    "        self.dense_transition1 = self.densenet.transition1 \n",
    "        self.dense_transition2 = nn.Sequential(nn.Conv2d(in_channels=512, out_channels=192, kernel_size=[1,1], stride=1, padding=0),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.AvgPool2d(kernel_size = [2, 2], stride=2, padding=0))\n",
    "        self.dense_transition3 = self.densenet.transition3\n",
    "\n",
    "        self.pooling = nn.AvgPool2d(kernel_size = [7, 7], stride=7, padding=0)\n",
    "        \n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 1)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.bn1d1 = nn.BatchNorm1d(2048)\n",
    "        self.bn1d2 = nn.BatchNorm1d(1024)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.scene_processor.apply(init_weights)\n",
    "        self.deep_feature_processor.apply(init_weights)\n",
    "        self.pre_input.apply(init_weights)\n",
    "\n",
    "        \n",
    "    @autocast()\n",
    "    def forward(self, imagelist, scene, device):\n",
    "        \n",
    "        deep_feature_in = []\n",
    "        \n",
    "        for feature in imagelist[1:20]:\n",
    "            feature = feature.float()\n",
    "            deep_feature_in.append(feature)\n",
    "            \n",
    "        deep_feature_in = torch.cat(deep_feature_in, dim=1)\n",
    "        \n",
    "        deep_feature_out = self.deep_feature_processor(deep_feature_in)\n",
    "\n",
    "        deep_feature_out = deep_feature_out.view(dense_out.size()[0], -1)\n",
    "        \n",
    "\n",
    "        scene_input = scene.float()\n",
    "\n",
    "        scene_out = self.scene_processor(scene_input)\n",
    "        \n",
    "        fc_in = torch.cat([deep_feature_out, scene_out], dim=1)\n",
    "        \n",
    "        fc_out = self.fc1(fc_in)\n",
    "        fc_out = self.bn1d1(fc_out)\n",
    "        fc_out = self.dropout1(fc_out)\n",
    "        fc_out = self.relu(fc_out)\n",
    "        \n",
    "        fc_out = self.fc2(fc_out)\n",
    "        fc_out = self.bn1d2(fc_out)\n",
    "        fc_out = self.dropout2(fc_out)\n",
    "        fc_out = self.relu(fc_out)\n",
    "        \n",
    "        fc_out = self.fc3(fc_out)\n",
    "        fc_out = self.sigmoid(fc_out)\n",
    "        \n",
    "        return fc_out\n",
    "\n",
    "    def name(self):\n",
    "        return \"FeatureNet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AugmentedDenseNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor p in model.module.deep_feature_processor.parameters():\\n    p.requires_grad == False\\n    \\nfor p in model.module.pre_input.parameters():\\n    p.requires_grad == False\\n    \\nfor p in model.module.dense_block3.parameters():\\n    p.requires_grad == False\\n        \\nfor p in model.module.dense_block4.parameters():\\n    p.requires_grad == False\\n        \\nfor p in model.module.dense_transition3.parameters():\\n    p.requires_grad == False\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for p in model.module.dense_input.parameters():\n",
    "    p.requires_grad == False\n",
    "\n",
    "for p in model.module.dense_block1.parameters():\n",
    "    p.requires_grad == False\n",
    "        \n",
    "for p in model.module.dense_block2.parameters():\n",
    "    p.requires_grad == False\n",
    "        \n",
    "for p in model.module.dense_transition1.parameters():\n",
    "    p.requires_grad == False\n",
    "        \n",
    "for p in model.module.dense_transition2.parameters():\n",
    "    p.requires_grad == False\n",
    "    \n",
    "'''\n",
    "for p in model.module.deep_feature_processor.parameters():\n",
    "    p.requires_grad == False\n",
    "    \n",
    "for p in model.module.pre_input.parameters():\n",
    "    p.requires_grad == False\n",
    "    \n",
    "for p in model.module.dense_block3.parameters():\n",
    "    p.requires_grad == False\n",
    "        \n",
    "for p in model.module.dense_block4.parameters():\n",
    "    p.requires_grad == False\n",
    "        \n",
    "for p in model.module.dense_transition3.parameters():\n",
    "    p.requires_grad == False\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization for single-GPU/CPU training ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-0d68792c75d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:1\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \"\"\"\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    374\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \"\"\"\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization for Data Parallel training ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.cuda()\n",
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic mixed-percision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_stats = {}\n",
    "training_stats['tarining_loss'] = []\n",
    "training_stats['validation_loss'] = []\n",
    "training_stats['accuracy'] = []\n",
    "training_stats['RMSE'] = []\n",
    "training_stats['spearmanr'] = []\n",
    "training_stats['classification'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpt(model_name, save_dir, epoch, model, optimizer, loss, accu, training_stats):\n",
    "    checkpoint_file = open(save_dir + \"\\\\\" + model_name + \"_\" + \"E\" + str(epoch) + \"A\" + str(int(accu*1000)) + \"_\" + time.strftime(\"%m.%d.%Y_%H.%M.%S\") \n",
    "                       + \".tar\", 'wb')\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            'training_stats': training_stats,\n",
    "            }, checkpoint_file)\n",
    "    checkpoint_file.close()\n",
    "\n",
    "\n",
    "model_name = \"DenseNet_Augmented_Binary_Paper\"\n",
    "checkpoint_save_dir = r\"I:\\Model Checkpoints\"\n",
    "best_accu = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> epoch: 0, batch index: 125, test loss ave(E): 0.305780, acc: 0.886472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.90      0.89      1999\n",
      "         1.0       0.90      0.87      0.88      2000\n",
      "\n",
      "    accuracy                           0.89      3999\n",
      "   macro avg       0.89      0.89      0.89      3999\n",
      "weighted avg       0.89      0.89      0.89      3999\n",
      "\n",
      "==================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-ee3062d08942>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mave_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mave_loss\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.99\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#back propagation with calculated loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "global epoch #declear epoch global, to be used later by torch.save() \n",
    "breakflag = False\n",
    "VALIDATION_FIRST = True\n",
    "\n",
    "for epoch in range(1):\n",
    "    \n",
    "    ave_loss = 0\n",
    "    global loss #declear loss global, to be used later by torch.save() \n",
    "\n",
    "\n",
    "    if epoch == 0 and VALIDATION_FIRST:\n",
    "        \n",
    "        f1_eval_storage = {'prediction':[], 'target':[]}\n",
    "        correct, ave_loss, total_cnt = 0, 0, 0\n",
    "        \n",
    "        for batch_idx, diction in enumerate(test_loader):\n",
    "            model.eval() #set model to evaluation mode\n",
    "        \n",
    "            imagelist, scene, target = diction['image'], diction['scene'], diction['rating'] #extract training data for this batch\n",
    "\n",
    "            target = target.to(device) \n",
    "            target = Variable(target)\n",
    "            target = target.float()\n",
    "\n",
    "            with autocast():\n",
    "                out = model(imagelist, scene, device=device) #forward pass\n",
    "                loss = criterion(out, target.long()) #calculate loss\n",
    "\n",
    "            pred_label = out.data\n",
    "            pred_label = pred_label.argmax(dim=1, keepdim=True)\n",
    "\n",
    "            target = target.long()\n",
    "\n",
    "            f1_eval_storage['prediction'] = np.append(f1_eval_storage['prediction'], pred_label.cpu().detach().numpy())\n",
    "            f1_eval_storage['target'] = np.append(f1_eval_storage['target'], target.cpu().detach().numpy())\n",
    "\n",
    "            total_cnt += scene.data.size()[0]\n",
    "            ave_loss = ave_loss * 0.99 + loss.item() * 0.01 #smooth average\n",
    "            correct += pred_label.eq(target.view_as(pred_label)).sum().item()\n",
    "\n",
    "            if (batch_idx + 1) == len(test_loader):\n",
    "                print(\n",
    "                '>>> epoch: {}, batch index: {}, test loss ave(E): {:.6f}, acc: {:.6f}'.format(\n",
    "                    epoch, batch_idx + 1, ave_loss, correct * 1.0 / total_cnt))\n",
    "                print(metrics.classification_report(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "                print('==================================================================') \n",
    "\n",
    "                #training_stats['accuracy'].append(correct * 1.0 / total_cnt)\n",
    "                #training_stats['validation_loss'].append(ave_loss)\n",
    "                #training_stats['classification'].append(metrics.classification_report(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "            \n",
    "                #save_checkpt(model_name, checkpoint_save_dir, epoch, model, optimizer, loss, accu=(correct * 1.0 / total_cnt), training_stats=training_stats)\n",
    "          \n",
    " \n",
    "    for batch_idx, diction in enumerate(train_loader):\n",
    "        model.train() #set model to traning mode\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        imagelist, scene, target = diction['image'], diction['scene'], diction['rating'] #extract training data for this batch\n",
    "        \n",
    "        target = target.to(device) \n",
    "        target = Variable(target)\n",
    "        target = target.float()\n",
    "\n",
    "        with autocast():\n",
    "            out = model(imagelist, scene, device=device) #forward pass\n",
    "            loss = criterion(out, target.long()) #calculate loss\n",
    "\n",
    "        ave_loss = ave_loss * 0.99 + loss.item() * 0.01 \n",
    "        \n",
    "        scaler.scale(loss).backward() #back propagation with calculated loss\n",
    "        scaler.step(optimizer) \n",
    "        scaler.update()\n",
    "\n",
    "        if (batch_idx + 1) == len(train_loader):\n",
    "            print('>>> epoch: {}, batch index: {}, train loss ave(E): {:.6f}'.format(epoch, batch_idx + 1, ave_loss))\n",
    "            training_stats['tarining_loss'].append(ave_loss)\n",
    "    \n",
    "            \n",
    "    f1_eval_storage = {'prediction':[], 'target':[]}\n",
    "    correct, ave_loss, total_cnt = 0, 0, 0\n",
    "    for batch_idx, diction in enumerate(val_loader):\n",
    "        model.eval() #set model to evaluation mode\n",
    "        \n",
    "        imagelist, scene, target = diction['image'], diction['scene'], diction['rating'] #extract training data for this batch\n",
    "        \n",
    "        target = target.to(device) \n",
    "        target = Variable(target)\n",
    "        target = target.float()\n",
    "        \n",
    "        with autocast():\n",
    "            out = model(imagelist, scene, device=device) #forward pass\n",
    "            loss = criterion(out, target.long()) #calculate loss\n",
    "\n",
    "        pred_label = out.data\n",
    "        pred_label = pred_label.argmax(dim=1, keepdim=True)\n",
    "        \n",
    "        target = target.long()\n",
    "        \n",
    "        f1_eval_storage['prediction'] = np.append(f1_eval_storage['prediction'], pred_label.cpu().detach().numpy())\n",
    "        f1_eval_storage['target'] = np.append(f1_eval_storage['target'], target.cpu().detach().numpy())\n",
    "        \n",
    "        total_cnt += scene.data.size()[0]\n",
    "        ave_loss = ave_loss * 0.99 + loss.item() * 0.01 #smooth average\n",
    "        correct += pred_label.eq(target.view_as(pred_label)).sum().item()\n",
    "        \n",
    "        if (batch_idx + 1) == len(val_loader):\n",
    "            print(\n",
    "            '>>> epoch: {}, batch index: {}, test loss ave(E): {:.6f}, acc: {:.6f}'.format(\n",
    "                epoch, batch_idx + 1, ave_loss, correct * 1.0 / total_cnt))\n",
    "            print(metrics.classification_report(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "            print('==================================================================') \n",
    "            \n",
    "            training_stats['accuracy'].append(correct * 1.0 / total_cnt)\n",
    "            training_stats['validation_loss'].append(ave_loss)\n",
    "            training_stats['classification'].append(metrics.classification_report(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "            \n",
    "            save_checkpt(model_name, checkpoint_save_dir, epoch, model, optimizer, loss, accu=(correct * 1.0 / total_cnt), training_stats=training_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear 10 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 0, batch index: 625, test loss: 0.005789, acc: 0.447\n",
      "RMSE: 0.6457722508088906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        34\n",
      "         2.0       0.58      0.02      0.04       641\n",
      "         3.0       0.53      0.07      0.12      5341\n",
      "         4.0       0.51      0.58      0.54     10093\n",
      "         5.0       0.35      0.73      0.47      3633\n",
      "         6.0       0.22      0.10      0.14       252\n",
      "         7.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.45     19999\n",
      "   macro avg       0.31      0.21      0.19     19999\n",
      "weighted avg       0.48      0.45      0.39     19999\n",
      "\n",
      "SpearmanrResult(correlation=0.580170286916907, pvalue=0.0)\n",
      "==================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\cuda\\nccl.py:14: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-7354388d1440>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiction\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#set model to traning mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\PD\\Datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "global epoch #declear epoch global, to be used later by torch.save() \n",
    "VALIDATION_FIRST = True\n",
    "\n",
    "for epoch in range(20):\n",
    "\n",
    "    ave_loss = 0\n",
    "    global loss #declear loss global, to be used later by torch.save() \n",
    "\n",
    "    if epoch == 0 and VALIDATION_FIRST:\n",
    "        \n",
    "        correct_cnt, ave_loss = 0, 0\n",
    "        total_cnt = 0\n",
    "        f1_eval_storage = {'prediction':[], 'target':[], 'pred_label':[]}\n",
    "        \n",
    "        for batch_idx, diction in enumerate(test_loader):\n",
    "            model.eval() #set model to evaluation mode\n",
    "\n",
    "            imagelist, scene, target = diction['image'], diction['scene'], diction['rating'] #extract training data for this batch\n",
    "            \n",
    "            target = target.to(device) \n",
    "            target = Variable(target)\n",
    "            target = target.float()\n",
    "\n",
    "            with autocast():\n",
    "                out = model(imagelist, scene, device=device) #forward pass\n",
    "                loss = criterion(out.squeeze(1), target / 10) #calculate loss\n",
    "\n",
    "            pred_label = np.around(out.cpu().detach().numpy() * 10)\n",
    "\n",
    "            target = target.long()\n",
    "            \n",
    "            f1_eval_storage['prediction'] = np.append(f1_eval_storage['prediction'], out.cpu().detach().numpy() * 10)\n",
    "            f1_eval_storage['target'] = np.append(f1_eval_storage['target'], target.cpu().detach().numpy())\n",
    "            f1_eval_storage['pred_label'] = np.append(f1_eval_storage['pred_label'], pred_label)\n",
    "\n",
    "            total_cnt += scene.data.size()[0]\n",
    "            # print(out, target.cpu().detach().numpy(), pred_label.squeeze(1))\n",
    "            correct_cnt += (pred_label.squeeze(1) == target.cpu().detach().numpy()).sum()\n",
    "            \n",
    "            ave_loss = ave_loss * 0.99 + loss.item() * 0.01 #smooth average\n",
    "\n",
    "            if (batch_idx + 1) == len(val_loader):\n",
    "                print(\n",
    "                '==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
    "                    epoch, batch_idx + 1, ave_loss, correct_cnt.item() * 1.0 / total_cnt))\n",
    "\n",
    "            if (batch_idx + 1) == len(val_loader):\n",
    "                training_stats['validation_loss'].append(ave_loss)\n",
    "                training_stats['accuracy'].append(correct_cnt.item() * 1.0 / total_cnt)\n",
    "                training_stats['RMSE'].append(metrics.mean_squared_error(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "                training_stats['spearmanr'].append(scipy.stats.spearmanr(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "                training_stats['classification'].append(metrics.classification_report(f1_eval_storage['target'], f1_eval_storage['pred_label']))\n",
    "                print('RMSE:', metrics.mean_squared_error(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "                print(metrics.classification_report(f1_eval_storage['target'], f1_eval_storage['pred_label']))\n",
    "                print(scipy.stats.spearmanr(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "                print('==================================================================') \n",
    "            \n",
    "\n",
    "    for batch_idx, diction in enumerate(train_loader):\n",
    "        \n",
    "        model.train() #set model to traning mode\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        imagelist, scene, target = diction['image'], diction['scene'], diction['rating'] #extract training data for this batch\n",
    "            \n",
    "        target = target.to(device) \n",
    "        target = Variable(target)\n",
    "        target = target.float()\n",
    "\n",
    "        with autocast():\n",
    "            out = model(imagelist, scene, device=device) #forward pass\n",
    "            loss = criterion(out.squeeze(1), target / 10) #calculate loss\n",
    "        \n",
    "        scaler.scale(loss).backward() #back propagation with calculated loss\n",
    "        scaler.step(optimizer) \n",
    "        scaler.update()\n",
    "        \n",
    "        ave_loss = ave_loss * 0.999 + loss.item() * 0.001 \n",
    "        \n",
    "        if (batch_idx + 1) == len(train_loader):\n",
    "            print('==>>> epoch: {}, batch index: {}, train loss: {:.6f}'.format(epoch, batch_idx + 1, loss))\n",
    "            training_stats['tarining_loss'].append(ave_loss)\n",
    "            \n",
    "\n",
    "    correct_cnt, ave_loss = 0, 0\n",
    "    total_cnt = 0\n",
    "    f1_eval_storage = {'prediction':[], 'target':[], 'pred_label':[]}\n",
    "    \n",
    "    for batch_idx, diction in enumerate(val_loader):\n",
    "        model.eval() #set model to evaluation mode\n",
    "\n",
    "        imagelist, scene, target = diction['image'], diction['scene'], diction['rating'] #extract training data for this batch\n",
    "\n",
    "        target = target.to(device) \n",
    "        target = Variable(target)\n",
    "        target = target.float()\n",
    "\n",
    "        with autocast():\n",
    "            out = model(imagelist, scene, device=device) #forward pass\n",
    "            loss = criterion(out.squeeze(1), target / 10) #calculate loss\n",
    "\n",
    "        pred_label = out.data\n",
    "        pred_label = np.around(out.cpu().detach().numpy() * 10)\n",
    "\n",
    "        target = target.long()\n",
    "\n",
    "        f1_eval_storage['prediction'] = np.append(f1_eval_storage['prediction'], out.cpu().detach().numpy() * 10)\n",
    "        f1_eval_storage['target'] = np.append(f1_eval_storage['target'], target.cpu().detach().numpy())\n",
    "        f1_eval_storage['pred_label'] = np.append(f1_eval_storage['pred_label'], pred_label)\n",
    "\n",
    "        total_cnt += scene.data.size()[0]\n",
    "        correct_cnt += (pred_label.squeeze(1) == target.cpu().detach().numpy()).sum()\n",
    "\n",
    "        ave_loss = ave_loss * 0.99 + loss.item() * 0.01 #smooth average\n",
    "\n",
    "        if (batch_idx + 1) == len(val_loader):\n",
    "            print(\n",
    "            '==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
    "                epoch, batch_idx + 1, ave_loss, correct_cnt.item() * 1.0 / total_cnt))\n",
    "\n",
    "        if (batch_idx + 1) == len(val_loader):\n",
    "            training_stats['validation_loss'].append(ave_loss)\n",
    "            training_stats['accuracy'].append(correct_cnt.item() * 1.0 / total_cnt)\n",
    "            training_stats['RMSE'].append(metrics.mean_squared_error(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "            training_stats['spearmanr'].append(scipy.stats.spearmanr(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "            training_stats['classification'].append(metrics.classification_report(f1_eval_storage['target'], f1_eval_storage['pred_label']))\n",
    "            \n",
    "            print('RMSE:', metrics.mean_squared_error(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "            print(metrics.classification_report(f1_eval_storage['target'], f1_eval_storage['pred_label']))\n",
    "            print(scipy.stats.spearmanr(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "            print('==================================================================') \n",
    "            \n",
    "            save_checkpt(model_name, checkpoint_save_dir, epoch, model, optimizer, loss, accu=(correct_cnt.item() * 1.0 / total_cnt), training_stats=training_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 3, batch index: 625, test loss: 0.005789, acc: 0.44682\n",
      "RMSE: 0.6457722508088906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        34\n",
      "         2.0       0.58      0.02      0.04       641\n",
      "         3.0       0.53      0.07      0.12      5341\n",
      "         4.0       0.51      0.58      0.54     10093\n",
      "         5.0       0.35      0.73      0.47      3633\n",
      "         6.0       0.22      0.10      0.14       252\n",
      "         7.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.45     19999\n",
      "   macro avg       0.31      0.21      0.19     19999\n",
      "weighted avg       0.48      0.45      0.39     19999\n",
      "\n",
      "SpearmanrResult(correlation=0.580170286916907, pvalue=0.0)\n",
      "==================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "f1_eval_storage = {'prediction':[], 'target':[], 'pred_label':[]}\n",
    "\n",
    "correct_cnt, ave_loss = 0, 0\n",
    "total_cnt = 0\n",
    "f1_eval_storage = {'prediction':[], 'target':[], 'pred_label':[]}\n",
    "    \n",
    "for batch_idx, diction in enumerate(test_loader):\n",
    "    model.eval() #set model to evaluation mode\n",
    "\n",
    "    imagelist, scene, target = diction['image'], diction['scene'], diction['rating'] #extract training data for this batch\n",
    "\n",
    "    target = target.to(device) \n",
    "    target = Variable(target)\n",
    "    target = target.float()\n",
    "\n",
    "    with autocast():\n",
    "        out = model(imagelist, scene, device=device) #forward pass\n",
    "        loss = criterion(out.squeeze(1), target / 10) #calculate loss\n",
    "\n",
    "    pred_label = np.around(out.cpu().detach().numpy() * 10)\n",
    "\n",
    "    target = target.long()\n",
    "\n",
    "    f1_eval_storage['prediction'] = np.append(f1_eval_storage['prediction'], out.cpu().detach().numpy() * 10)\n",
    "    f1_eval_storage['target'] = np.append(f1_eval_storage['target'], target.cpu().detach().numpy())\n",
    "    f1_eval_storage['pred_label'] = np.append(f1_eval_storage['pred_label'], pred_label)\n",
    "\n",
    "    total_cnt += scene.data.size()[0]\n",
    "    # print(out, target.cpu().detach().numpy(), pred_label.squeeze(1))\n",
    "    correct_cnt += (pred_label.squeeze(1) == target.cpu().detach().numpy()).sum()\n",
    "\n",
    "    ave_loss = ave_loss * 0.99 + loss.item() * 0.01 #smooth average\n",
    "\n",
    "    if (batch_idx + 1) == len(test_loader):\n",
    "        print(\n",
    "        '==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.5f}'.format(\n",
    "            epoch, batch_idx + 1, ave_loss, correct_cnt.item() * 1.0 / total_cnt))\n",
    "\n",
    "        training_stats['validation_loss'].append(ave_loss)\n",
    "        training_stats['accuracy'].append(correct_cnt.item() * 1.0 / total_cnt)\n",
    "        training_stats['RMSE'].append(metrics.mean_squared_error(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "        training_stats['spearmanr'].append(scipy.stats.spearmanr(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "        training_stats['classification'].append(metrics.classification_report(f1_eval_storage['target'], f1_eval_storage['pred_label']))\n",
    "        print('RMSE:', metrics.mean_squared_error(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "        print(metrics.classification_report(f1_eval_storage['target'], f1_eval_storage['pred_label']))\n",
    "        print(scipy.stats.spearmanr(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "        print('==================================================================') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear threshold to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 3, batch index: 125, test loss: 0.103529, acc: 0.88572\n",
      "RMSE: 14.468474600606633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.83      0.88      1999\n",
      "         1.0       0.85      0.94      0.89      2000\n",
      "\n",
      "    accuracy                           0.89      3999\n",
      "   macro avg       0.89      0.89      0.89      3999\n",
      "weighted avg       0.89      0.89      0.89      3999\n",
      "\n",
      "SpearmanrResult(correlation=0.7989365473510059, pvalue=0.0)\n",
      "==================================================================\n",
      "4.280794319673668\n"
     ]
    }
   ],
   "source": [
    "f1_eval_storage = {'prediction':[], 'target':[], 'pred_label':[]}\n",
    "correct_cnt, ave_loss = 0, 0\n",
    "total_cnt = 0\n",
    "\n",
    "for batch_idx, diction in enumerate(val_loader):\n",
    "    model.eval() #set model to evaluation mode\n",
    "\n",
    "    imagelist, scene, target = diction['image'], diction['scene'], diction['rating'] #extract training data for this batch\n",
    "\n",
    "    target = target.float()\n",
    "    target = target.to(device) \n",
    "    target = Variable(target)\n",
    "\n",
    "    with autocast():\n",
    "        out = model(imagelist, scene, device=device) #forward pass\n",
    "        loss = criterion(out.squeeze(1), target / 10) #calculate loss\n",
    "\n",
    "    #pred_label = np.around(out.cpu().detach().numpy() * 10)\n",
    "    pred_label = out.cpu().detach().numpy() * 10\n",
    "    \n",
    "    for idx, label in enumerate(pred_label):\n",
    "        if label >= 4.21419246:\n",
    "            pred_label[idx] = 1\n",
    "        else:\n",
    "            pred_label[idx] = 0\n",
    "    \n",
    "    target = target.long()\n",
    "    \n",
    "    # print(target, pred_label)\n",
    "\n",
    "    f1_eval_storage['prediction'] = np.append(f1_eval_storage['prediction'], out.cpu().detach().numpy() * 10)\n",
    "    f1_eval_storage['target'] = np.append(f1_eval_storage['target'], target.cpu().detach().numpy())\n",
    "    f1_eval_storage['pred_label'] = np.append(f1_eval_storage['pred_label'], pred_label)\n",
    "\n",
    "    total_cnt += scene.data.size()[0]\n",
    "    correct_cnt += (pred_label.squeeze(1) == target.cpu().detach().numpy()).sum()\n",
    "\n",
    "    ave_loss = ave_loss * 0.99 + loss.item() * 0.01 #smooth average\n",
    "\n",
    "    if (batch_idx + 1) == len(val_loader):\n",
    "        print(\n",
    "        '==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.5f}'.format(\n",
    "            epoch, batch_idx + 1, ave_loss, correct_cnt.item() * 1.0 / total_cnt))\n",
    "\n",
    "        training_stats['validation_loss'].append(ave_loss)\n",
    "        training_stats['accuracy'].append(correct_cnt.item() * 1.0 / total_cnt)\n",
    "        training_stats['RMSE'].append(metrics.mean_squared_error(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "        training_stats['spearmanr'].append(scipy.stats.spearmanr(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "        training_stats['classification'].append(metrics.classification_report(f1_eval_storage['target'], f1_eval_storage['pred_label']))\n",
    "        \n",
    "        print('RMSE:', metrics.mean_squared_error(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "        print(metrics.classification_report(f1_eval_storage['target'], f1_eval_storage['pred_label']))\n",
    "        print(scipy.stats.spearmanr(f1_eval_storage['target'], f1_eval_storage['prediction']))\n",
    "        print('==================================================================') \n",
    "        print(np.average(f1_eval_storage['prediction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics, Saving, Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      1.00      0.01        60\n",
      "         2.0       0.00      0.00      0.00       684\n",
      "         3.0       0.00      0.00      0.00      5517\n",
      "         4.0       0.00      0.00      0.00     10089\n",
      "         5.0       0.00      0.00      0.00      3381\n",
      "         6.0       0.00      0.00      0.00       263\n",
      "         7.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.00     19999\n",
      "   macro avg       0.00      0.14      0.00     19999\n",
      "weighted avg       0.00      0.00      0.00     19999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# print(scipy.stats.spearmanr((f1_eval_storage['target'], f1_eval_storage['prediction'])))\n",
    "print(metrics.classification_report(f1_eval_storage['target'], f1_eval_storage['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pthflops import count_ops\n",
    "\n",
    "model.eval()\n",
    "\n",
    "inp = torch.Tensor(np.zeros(150528).reshape(1, 3, 224, 224))\n",
    "\n",
    "inp = inp.cuda()\n",
    "inp = inp.to(torch.device(\"cuda:0\"))\n",
    "\n",
    "count_ops(model, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Augmented_Densenet_Smooth\"\n",
    "checkpoint_save_dir = r\"C:\\Users\\Leo's PC\\PycharmProjects\\PD\\Model Checkpoints\"\n",
    "checkpoint_file = open(checkpoint_save_dir + \"\\\\\" + model_name + \"_\" + \"E\" + str(20) + \"_\" + time.strftime(\"%m.%d.%Y_%H.%M.%S\") \n",
    "                       + \".tar\", 'wb')\n",
    "\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            'training_stats': training_stats\n",
    "            }, checkpoint_file)\n",
    "\n",
    "checkpoint_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.92601882e-02 2.79390397e-08]\n",
      " [4.98329541e-01 0.00000000e+00]\n",
      " [5.36470731e-01 0.00000000e+00]\n",
      " [5.43768941e-01 0.00000000e+00]\n",
      " [5.51300459e-01 0.00000000e+00]\n",
      " [5.63593776e-01 0.00000000e+00]]\n",
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Augmented DenseNet - Linear Regression')\n",
    "\n",
    "plt.plot(np.arange(len(training_stats['tarining_loss'])), training_stats['tarining_loss'], label='tarining loss')\n",
    "plt.plot(np.arange(len(training_stats['validation_loss'])), training_stats['validation_loss'], label='validation loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.ylabel('accu/RMSE/rho')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Augmented DenseNet - Linear Regression')\n",
    "\n",
    "plt.plot(np.arange(len(training_stats['accuracy'])), training_stats['accuracy'], label='accuracy')\n",
    "#plt.plot(np.arange(len(training_stats['classification'])), training_stats['classification'], label='')\n",
    "plt.plot(np.arange(len(training_stats['RMSE'])), training_stats['RMSE'], label='RMSE')\n",
    "plt.plot(np.arange(len(training_stats['spearmanr'])), [i[0] for i in training_stats['spearmanr']], label=\"Spearman's rho\")\n",
    "\n",
    "print(np.array(training_stats['spearmanr']))\n",
    "print(len(np.array(training_stats['spearmanr'])))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Resource/Dense_Augmented_Smooth_logdataPaper.pkl', 'wb') as fp:\n",
    "        pickle.dump(training_stats, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(open(checkpoint_save_dir + \"\\DenseNet_Augmented_Binary_Paper_E10A865_10.12.2020_02.37.11.tar\", 'rb'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "training_stats = checkpoint['training_stats']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after input. size: torch.Size([2, 64, 56, 56])\n",
    "after block1. size: torch.Size([2, 128, 28, 28])\n",
    "after block2. size: torch.Size([2, 256, 14, 14])\n",
    "after block3. size: torch.Size([2, 640, 7, 7])\n",
    "after block4. size: torch.Size([2, 1664, 7, 7])\n",
    "after pooling. size: torch.Size([2, 1664, 1, 1])\n",
    "\n",
    ".resize_([batch_size, 1])\n",
    ".resize_([batch_size, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
